{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":6356268,"sourceType":"datasetVersion","datasetId":3660994}],"dockerImageVersionId":30626,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn import model_selection, metrics, preprocessing\nimport torch\nimport torch.nn as nn\nimport matplotlib.pyplot as plt \nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn.functional as F\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-02-21T06:22:41.714287Z","iopub.execute_input":"2024-02-21T06:22:41.714809Z","iopub.status.idle":"2024-02-21T06:22:41.723080Z","shell.execute_reply.started":"2024-02-21T06:22:41.714773Z","shell.execute_reply":"2024-02-21T06:22:41.721839Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/movielens-9000-movies-dataset/ml-latest-small/ratings.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-02-21T06:22:41.725704Z","iopub.execute_input":"2024-02-21T06:22:41.726131Z","iopub.status.idle":"2024-02-21T06:22:41.812558Z","shell.execute_reply.started":"2024-02-21T06:22:41.726096Z","shell.execute_reply":"2024-02-21T06:22:41.811231Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"df.info() # basically show schema","metadata":{"execution":{"iopub.status.busy":"2024-02-21T06:22:41.814363Z","iopub.execute_input":"2024-02-21T06:22:41.814876Z","iopub.status.idle":"2024-02-21T06:22:41.834770Z","shell.execute_reply.started":"2024-02-21T06:22:41.814805Z","shell.execute_reply":"2024-02-21T06:22:41.833479Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 100836 entries, 0 to 100835\nData columns (total 4 columns):\n #   Column     Non-Null Count   Dtype  \n---  ------     --------------   -----  \n 0   userId     100836 non-null  int64  \n 1   movieId    100836 non-null  int64  \n 2   rating     100836 non-null  float64\n 3   timestamp  100836 non-null  int64  \ndtypes: float64(1), int64(3)\nmemory usage: 3.1 MB\n","output_type":"stream"}]},{"cell_type":"code","source":"df.userId.nunique()","metadata":{"execution":{"iopub.status.busy":"2024-02-21T06:22:41.836574Z","iopub.execute_input":"2024-02-21T06:22:41.836930Z","iopub.status.idle":"2024-02-21T06:22:41.847460Z","shell.execute_reply.started":"2024-02-21T06:22:41.836891Z","shell.execute_reply":"2024-02-21T06:22:41.845709Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"610"},"metadata":{}}]},{"cell_type":"code","source":"df.movieId.nunique()","metadata":{"execution":{"iopub.status.busy":"2024-02-21T06:22:41.852399Z","iopub.execute_input":"2024-02-21T06:22:41.852944Z","iopub.status.idle":"2024-02-21T06:22:41.863224Z","shell.execute_reply.started":"2024-02-21T06:22:41.852896Z","shell.execute_reply":"2024-02-21T06:22:41.861656Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"9724"},"metadata":{}}]},{"cell_type":"code","source":"df.rating.value_counts() #check value distribution","metadata":{"execution":{"iopub.status.busy":"2024-02-21T06:22:41.865347Z","iopub.execute_input":"2024-02-21T06:22:41.865836Z","iopub.status.idle":"2024-02-21T06:22:41.880557Z","shell.execute_reply.started":"2024-02-21T06:22:41.865793Z","shell.execute_reply":"2024-02-21T06:22:41.879083Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"rating\n4.0    26818\n3.0    20047\n5.0    13211\n3.5    13136\n4.5     8551\n2.0     7551\n2.5     5550\n1.0     2811\n1.5     1791\n0.5     1370\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2024-02-21T06:22:41.882592Z","iopub.execute_input":"2024-02-21T06:22:41.883003Z","iopub.status.idle":"2024-02-21T06:22:41.891948Z","shell.execute_reply.started":"2024-02-21T06:22:41.882937Z","shell.execute_reply":"2024-02-21T06:22:41.890648Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"(100836, 4)"},"metadata":{}}]},{"cell_type":"code","source":"# Get the number of unique users and movies\nn_users = df.userId.nunique()\nn_movies = df.movieId.max() + 1\n\n","metadata":{"execution":{"iopub.status.busy":"2024-02-21T06:22:41.893891Z","iopub.execute_input":"2024-02-21T06:22:41.894362Z","iopub.status.idle":"2024-02-21T06:22:41.904552Z","shell.execute_reply.started":"2024-02-21T06:22:41.894330Z","shell.execute_reply":"2024-02-21T06:22:41.903194Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"class MovieDataset:\n    def __init__(self, df, n_users, n_movies):\n        self.users = df.userId.values\n        self.movies = df.movieId.values\n        self.ratings = df.rating.values\n        self.n_users = n_users\n        self.n_movies = n_movies\n\n    def __len__(self):\n        return len(self.users)\n\n    def __getitem__(self, item):\n        user = self.users[item]\n        movie = self.movies[item]\n        rating = self.ratings[item]\n\n        # Check and correct user index\n        if user >= self.n_users:\n            user = self.n_users - 1\n\n        # One-hot encode user and movie IDs\n        user_onehot = torch.zeros(self.n_users)\n        user_onehot[user] = 1.0\n\n        movie_onehot = torch.zeros(self.n_movies)\n        movie_onehot[movie] = 1.0\n\n        return {\n            \"users_onehot\": user_onehot,\n            \"movies_onehot\": movie_onehot,\n            \"ratings\": torch.tensor(rating, dtype=torch.float32),\n        }\n\n# Create an instance of MovieDataset with your data\ndataset = MovieDataset(df, n_users, n_movies)\n\n# Check the max indices\nprint(\"Max user index:\", dataset.users.max())\nprint(\"Max movie index:\", dataset.movies.max())","metadata":{"execution":{"iopub.status.busy":"2024-02-21T06:22:41.907013Z","iopub.execute_input":"2024-02-21T06:22:41.907673Z","iopub.status.idle":"2024-02-21T06:22:41.920563Z","shell.execute_reply.started":"2024-02-21T06:22:41.907635Z","shell.execute_reply":"2024-02-21T06:22:41.919587Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"Max user index: 610\nMax movie index: 193609\n","output_type":"stream"}]},{"cell_type":"code","source":"class RecSysModel(nn.Module):\n    def __init__(self, n_users, n_movies, emb_size=32):\n        super().__init__()\n        self.user_embed = nn.Linear(n_users, emb_size, bias=False)\n        self.movie_embed = nn.Linear(n_movies, emb_size, bias=False)\n        self.hidden1 = nn.Linear(emb_size * 2, 32)\n        self.hidden2 = nn.Linear(32, 16)\n        self.hidden3 = nn.Linear(16, 8)\n        self.out = nn.Linear(8, 1)\n\n    def forward(self, users_onehot, movies_onehot):\n        user_embeds = self.user_embed(users_onehot)\n        movie_embeds = self.movie_embed(movies_onehot)\n        user_embeds = user_embeds.view(-1, user_embeds.size(1))\n        movie_embeds = movie_embeds.view(-1, movie_embeds.size(1))\n        embedding = torch.cat([user_embeds, movie_embeds], dim=1)\n        embedding = F.relu(self.hidden1(embedding))\n        embedding = F.relu(self.hidden2(embedding))\n        embedding = F.relu(self.hidden3(embedding))\n        output = self.out(embedding)\n        return output\n\n    def predict_ratings(self, users_onehot, movies_onehot):\n        with torch.no_grad():\n            output = self(users_onehot, movies_onehot)\n        return output.squeeze().tolist()  # Convert tensor to list of ratings","metadata":{"execution":{"iopub.status.busy":"2024-02-21T06:22:41.922256Z","iopub.execute_input":"2024-02-21T06:22:41.923161Z","iopub.status.idle":"2024-02-21T06:22:41.938042Z","shell.execute_reply.started":"2024-02-21T06:22:41.923109Z","shell.execute_reply":"2024-02-21T06:22:41.937139Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"\nfrom sklearn.model_selection import train_test_split\n\n# Assuming 'userId' is the column representing users in your DataFrame\ndf_train, df_valid = train_test_split(df, test_size=0.1, random_state=42, stratify=df['userId'].values)\nprint(\"Size of Training Set:\", len(df_train))\nprint(\"Size of Validation Set:\", len(df_valid))\n\n# Create datasets\ntrain_dataset = MovieDataset(df_train, n_users, n_movies)\nvalid_dataset = MovieDataset(df_valid, n_users, n_movies)\n\n# Create data loaders\ntrain_loader = DataLoader(dataset=train_dataset, batch_size=4, shuffle=True, num_workers=2)\nvalidation_loader = DataLoader(dataset=valid_dataset, batch_size=4, shuffle=True, num_workers=2)\n#print(\"Unique User IDs in Training Set (Sorted):\")\n#print(sorted(df_train['userId'].unique()))\n\n#print(\"\\nUnique User IDs in Validation Set (Sorted):\")\n#print(sorted(df_valid['userId'].unique()))\n","metadata":{"execution":{"iopub.status.busy":"2024-02-21T06:22:41.939255Z","iopub.execute_input":"2024-02-21T06:22:41.939665Z","iopub.status.idle":"2024-02-21T06:22:42.041664Z","shell.execute_reply.started":"2024-02-21T06:22:41.939632Z","shell.execute_reply":"2024-02-21T06:22:42.040316Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"Size of Training Set: 90752\nSize of Validation Set: 10084\n","output_type":"stream"}]},{"cell_type":"code","source":"# Choose the first user ID (assuming user IDs start from 1)\nfirst_user_id = 1\n\n# Filter the training set for the first user\ntraining_ratings_first_user = df_train[df_train['userId'] == first_user_id]\n\n# Filter the validation set for the first user\nvalidation_ratings_first_user = df_valid[df_valid['userId'] == first_user_id]\n\n# Print information for the training set\nprint(f\"Training Set - User {first_user_id} Ratings:\")\nprint(training_ratings_first_user[['movieId', 'rating']])\n\n# Print information for the validation set\nprint(f\"\\nValidation Set - User {first_user_id} Ratings:\")\nprint(validation_ratings_first_user[['movieId', 'rating']])\n","metadata":{"execution":{"iopub.status.busy":"2024-02-21T06:22:42.043519Z","iopub.execute_input":"2024-02-21T06:22:42.044233Z","iopub.status.idle":"2024-02-21T06:22:42.065760Z","shell.execute_reply.started":"2024-02-21T06:22:42.044192Z","shell.execute_reply":"2024-02-21T06:22:42.064426Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"Training Set - User 1 Ratings:\n     movieId  rating\n134     2115     5.0\n99      1552     4.0\n143     2253     2.0\n76      1219     2.0\n48       954     5.0\n..       ...     ...\n204     3168     4.0\n186     2899     5.0\n132     2099     4.0\n170     2617     2.0\n3         47     5.0\n\n[209 rows x 2 columns]\n\nValidation Set - User 1 Ratings:\n     movieId  rating\n109     1777     4.0\n32       590     4.0\n216     3479     4.0\n53      1029     5.0\n141     2174     4.0\n168     2596     5.0\n193     2985     4.0\n145     2273     4.0\n67      1136     5.0\n81      1240     5.0\n47       943     4.0\n207     3247     3.0\n188     2944     5.0\n92      1377     3.0\n20       356     4.0\n98      1517     5.0\n127     2078     5.0\n160     2478     4.0\n226     3740     4.0\n162     2502     5.0\n152     2389     2.0\n111     1804     5.0\n83      1258     3.0\n","output_type":"stream"}]},{"cell_type":"code","source":"dataiter = iter(train_loader)\n\nfor dataloader_data in dataiter:\n    print(dataloader_data)\n    break","metadata":{"execution":{"iopub.status.busy":"2024-02-21T06:22:42.072062Z","iopub.execute_input":"2024-02-21T06:22:42.072551Z","iopub.status.idle":"2024-02-21T06:22:42.200120Z","shell.execute_reply.started":"2024-02-21T06:22:42.072511Z","shell.execute_reply":"2024-02-21T06:22:42.198071Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"{'users_onehot': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.]]), 'movies_onehot': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.]]), 'ratings': tensor([4.5000, 4.0000, 3.5000, 4.0000])}\n","output_type":"stream"}]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","metadata":{"execution":{"iopub.status.busy":"2024-02-21T06:22:42.202896Z","iopub.execute_input":"2024-02-21T06:22:42.204288Z","iopub.status.idle":"2024-02-21T06:22:42.212323Z","shell.execute_reply.started":"2024-02-21T06:22:42.204230Z","shell.execute_reply":"2024-02-21T06:22:42.210877Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"model = RecSysModel(\n    n_users, n_movies, emb_size=32\n).to(device)\n\n# Optimizer and scheduler\n#optimizer = torch.optim.Adam(model.parameters())\noptimizer = torch.optim.Adam(model.parameters(), lr=0.0001)  # Setting learning rate to 0.001\n\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.7)\n\n# Loss function\nloss_func = nn.MSELoss()","metadata":{"execution":{"iopub.status.busy":"2024-02-21T06:22:42.214303Z","iopub.execute_input":"2024-02-21T06:22:42.215406Z","iopub.status.idle":"2024-02-21T06:22:42.305992Z","shell.execute_reply.started":"2024-02-21T06:22:42.215354Z","shell.execute_reply":"2024-02-21T06:22:42.304612Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"print(n_users)\nprint(n_movies)\nprint(df.movieId.max() + 1)  # Adding 1 because movieId starts from 0 after one-hot encoding\nprint(len(train_dataset))\n","metadata":{"execution":{"iopub.status.busy":"2024-02-21T06:22:42.307748Z","iopub.execute_input":"2024-02-21T06:22:42.308202Z","iopub.status.idle":"2024-02-21T06:22:42.318227Z","shell.execute_reply.started":"2024-02-21T06:22:42.308165Z","shell.execute_reply":"2024-02-21T06:22:42.316985Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"610\n193610\n193610\n90752\n","output_type":"stream"}]},{"cell_type":"code","source":"with torch.no_grad():\n    model_output = model(dataloader_data['users_onehot'], \n                         dataloader_data['movies_onehot'])\n\n    print(f\"model_output: {model_output}, size: {model_output.size()}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-02-21T06:22:42.321897Z","iopub.execute_input":"2024-02-21T06:22:42.322589Z","iopub.status.idle":"2024-02-21T06:22:42.351554Z","shell.execute_reply.started":"2024-02-21T06:22:42.322540Z","shell.execute_reply":"2024-02-21T06:22:42.350518Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"model_output: tensor([[-0.2784],\n        [-0.2784],\n        [-0.2789],\n        [-0.2793]]), size: torch.Size([4, 1])\n","output_type":"stream"}]},{"cell_type":"code","source":"rating = dataloader_data[\"ratings\"]\nprint(rating)\nprint(rating.view(4, -1))\nprint(model_output)\n\nprint(rating.sum())\n\nprint(model_output.sum() - rating.sum())","metadata":{"execution":{"iopub.status.busy":"2024-02-21T06:22:42.353134Z","iopub.execute_input":"2024-02-21T06:22:42.354155Z","iopub.status.idle":"2024-02-21T06:22:42.368455Z","shell.execute_reply.started":"2024-02-21T06:22:42.354114Z","shell.execute_reply":"2024-02-21T06:22:42.367237Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"tensor([4.5000, 4.0000, 3.5000, 4.0000])\ntensor([[4.5000],\n        [4.0000],\n        [3.5000],\n        [4.0000]])\ntensor([[-0.2784],\n        [-0.2784],\n        [-0.2789],\n        [-0.2793]])\ntensor(16.)\ntensor(-17.1150)\n","output_type":"stream"}]},{"cell_type":"code","source":"epochs = 1\ntotal_loss = 0\nplot_steps, print_steps = 5000, 5000\nstep_cnt = 0\nall_losses_list = [] \n\nmodel.train() \nfor epoch_i in range(epochs):\n    for i, train_data in enumerate(train_loader):\n        output = model(train_data[\"users_onehot\"], \n                       train_data[\"movies_onehot\"]\n                      ) \n        \n        rating = train_data[\"ratings\"].view(4, -1).to(torch.float32)\n\n        # Calculate IPS for each batch\n        ips = 1 / train_data['users_onehot'].sum(dim=1)  # Assuming each user rated each movie only once\n\n        loss = loss_func(output, rating)\n        \n        # Weight the loss by IPS\n        weighted_loss = (loss * ips).mean()\n        \n        total_loss = total_loss + weighted_loss.sum().item()\n        optimizer.zero_grad()\n        weighted_loss.backward()\n        optimizer.step()\n\n        step_cnt = step_cnt + len(train_data[\"users_onehot\"])\n        \n\n        if(step_cnt % plot_steps == 0):\n            avg_loss = total_loss/(len(train_data[\"users_onehot\"]) * plot_steps)\n            print(f\"epoch {epoch_i} loss at step: {step_cnt} is {avg_loss}\")\n            all_losses_list.append(avg_loss)\n            total_loss = 0  # reset total_loss","metadata":{"execution":{"iopub.status.busy":"2024-02-21T06:22:42.369858Z","iopub.execute_input":"2024-02-21T06:22:42.370998Z","iopub.status.idle":"2024-02-21T06:54:29.386926Z","shell.execute_reply.started":"2024-02-21T06:22:42.370946Z","shell.execute_reply":"2024-02-21T06:54:29.385312Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"epoch 0 loss at step: 5000 is 0.8061426750063896\nepoch 0 loss at step: 10000 is 0.1403515764215961\nepoch 0 loss at step: 15000 is 0.06707441809419543\nepoch 0 loss at step: 20000 is 0.059902962026000026\nepoch 0 loss at step: 25000 is 0.05453673442741856\nepoch 0 loss at step: 30000 is 0.0536508630909957\nepoch 0 loss at step: 35000 is 0.05080701299542561\nepoch 0 loss at step: 40000 is 0.05243462227038108\nepoch 0 loss at step: 45000 is 0.0537216806601733\nepoch 0 loss at step: 50000 is 0.04953235822473653\nepoch 0 loss at step: 55000 is 0.04982311040898785\nepoch 0 loss at step: 60000 is 0.049438776783971114\nepoch 0 loss at step: 65000 is 0.04628924356345087\nepoch 0 loss at step: 70000 is 0.050503423836594445\nepoch 0 loss at step: 75000 is 0.047363646966940724\nepoch 0 loss at step: 80000 is 0.046422646675398575\nepoch 0 loss at step: 85000 is 0.05174644077187404\nepoch 0 loss at step: 90000 is 0.04987861755418126\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\n\nmodel_output_list = []\ntarget_rating_list = []\n\nmodel.eval()\n\nwith torch.no_grad():\n    for i, batched_data in enumerate(validation_loader): \n        model_output = model(batched_data['users_onehot'], \n                             batched_data['movies_onehot'])\n        \n        model_output_list.append(model_output.sum().item() / len(batched_data['users_onehot']))\n\n        target_rating = batched_data[\"ratings\"]\n        \n        target_rating_list.append(target_rating.sum().item() / len(batched_data['users_onehot']))\n\n# squared If True returns MSE value, if False returns RMSE value.\nrms = mean_squared_error(target_rating_list, model_output_list, squared=False)\nprint(f\"rms: {rms}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-02-21T06:54:29.389537Z","iopub.execute_input":"2024-02-21T06:54:29.390272Z","iopub.status.idle":"2024-02-21T06:54:53.400871Z","shell.execute_reply.started":"2024-02-21T06:54:29.390213Z","shell.execute_reply":"2024-02-21T06:54:53.399320Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"rms: 0.43412024547893985\n","output_type":"stream"}]},{"cell_type":"code","source":"predicted_ratings_list = []\n\nwith torch.no_grad():\n    for i, batched_data in enumerate(validation_loader): \n        \n        model_output = model(batched_data['users_onehot'], batched_data['movies_onehot'])\n        \n        for user_idx in range(len(batched_data['users_onehot'])):\n            # Get the index of the test item (movie with the highest rating)\n            test_item_index = torch.argmax(batched_data[\"ratings\"][user_idx]).item()\n\n            # Predict rating for the test item\n            predicted_rating = model_output[user_idx, test_item_index].item()\n            predicted_ratings_list.append(predicted_rating)\n\n        \n# Calculate average predicted rating\naverage_predicted_rating = np.mean(predicted_ratings_list)\nprint(f\"Average Predicted Rating of Test Item: {average_predicted_rating}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-02-21T06:54:53.403043Z","iopub.execute_input":"2024-02-21T06:54:53.404003Z","iopub.status.idle":"2024-02-21T06:55:17.760410Z","shell.execute_reply.started":"2024-02-21T06:54:53.403921Z","shell.execute_reply":"2024-02-21T06:55:17.758807Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"Average Predicted Rating of Test Item: 3.514879858408689\n","output_type":"stream"}]},{"cell_type":"code","source":"print(df.movieId.max() + 1)","metadata":{"execution":{"iopub.status.busy":"2024-02-21T06:55:17.765284Z","iopub.execute_input":"2024-02-21T06:55:17.766829Z","iopub.status.idle":"2024-02-21T06:55:17.776660Z","shell.execute_reply.started":"2024-02-21T06:55:17.766760Z","shell.execute_reply":"2024-02-21T06:55:17.775070Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"193610\n","output_type":"stream"}]},{"cell_type":"code","source":"# Set the model to evaluation mode\nmodel.eval()\n\n# Initialize variables to track hits\nhits_count = 0\ntotal_users = 0\n\n# Iterate over each user\nfor user_id in df['userId'].unique():\n    if user_id == 610:\n        continue \n    # Get movies rated by the user\n    rated_movies = df[df['userId'] == user_id]\n    \n    # Sample 100 unrated movie IDs if available\n    unrated_movie_ids = df[~df['movieId'].isin(rated_movies['movieId'])]['movieId'].unique()\n    sampled_movie_ids = np.random.choice(unrated_movie_ids, size=min(100, len(unrated_movie_ids)), replace=False)\n    \n    # Append the highest rated movie for the user\n    highest_rated_movie_id = rated_movies.nlargest(1, 'rating')['movieId'].values[0]\n    sampled_movie_ids = np.append(sampled_movie_ids, highest_rated_movie_id)\n    \n    # Initialize list to store movie ratings\n    movie_ratings = []\n    \n    # Iterate over each sampled movie\n    for movie_id in sampled_movie_ids:\n        # One-hot encode user and movie\n        user_tensor = torch.tensor([user_id], dtype=torch.long)\n        movie_tensor = torch.tensor([movie_id], dtype=torch.long)\n        \n        user_onehot = torch.zeros(1, n_users)\n        user_onehot[0, user_id] = 1.0\n        \n        movie_onehot = torch.zeros(1, n_movies)\n        movie_onehot[0, movie_id] = 1.0\n        \n        # Get predictions from the model\n        model_output = model(user_onehot, movie_onehot)\n        \n        # Store the movie ID and its predicted rating\n        movie_ratings.append((movie_id, model_output.item()))  # Assuming model_output contains the predicted rating\n    \n    # Sort the movie ratings based on predicted ratings\n    movie_ratings.sort(key=lambda x: x[1], reverse=True)\n    \n    # Check if the highest rated item is among the top 10 recommendations\n    top_10_recommendations = [movie_id for movie_id, _ in movie_ratings[:10]]\n    if highest_rated_movie_id in top_10_recommendations:\n        hits_count += 1\n    \n    total_users += 1\n\n# Calculate hit rate\nhit_rate = hits_count / total_users if total_users > 0 else 0\nprint(\"Hit rate:\", hit_rate)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-21T06:55:17.778899Z","iopub.execute_input":"2024-02-21T06:55:17.779502Z","iopub.status.idle":"2024-02-21T06:57:04.974901Z","shell.execute_reply.started":"2024-02-21T06:55:17.779456Z","shell.execute_reply":"2024-02-21T06:57:04.973754Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"Hit rate: 0.8078817733990148\n","output_type":"stream"}]},{"cell_type":"code","source":"# Set the model to evaluation mode\nmodel.eval()\n\n# Initialize variables to track hits\nhits_count_top20 = 0\nhits_count_bottom20 = 0\ntotal_users_top20 = 0\ntotal_users_bottom20 = 0\n\n# Get the number of ratings provided by each user\nuser_rating_counts = df['userId'].value_counts()\n\n# Sort users based on the number of ratings they have provided\nsorted_users = user_rating_counts.index.tolist()\n\n# Select the top 20 and bottom 20 frequent users\ntop20_users = sorted_users[:20]\nbottom20_users = sorted_users[-20:]\n\n# Iterate over each user\nfor user_id in df['userId'].unique():\n    # Skip user 610\n    if user_id == 610:\n        continue\n    \n    # Get movies rated by the user\n    rated_movies = df[df['userId'] == user_id]\n    \n    # Sample 100 unrated movie IDs if available\n    unrated_movie_ids = df[~df['movieId'].isin(rated_movies['movieId'])]['movieId'].unique()\n    sampled_movie_ids = np.random.choice(unrated_movie_ids, size=min(100, len(unrated_movie_ids)), replace=False)\n    \n    # Append the highest rated movie for the user\n    highest_rated_movie_id = rated_movies.nlargest(1, 'rating')['movieId'].values[0]\n    sampled_movie_ids = np.append(sampled_movie_ids, highest_rated_movie_id)\n    \n    # Initialize list to store movie ratings\n    movie_ratings = []\n    \n    # Iterate over each sampled movie\n    for movie_id in sampled_movie_ids:\n        # One-hot encode user and movie\n        user_tensor = torch.tensor([user_id], dtype=torch.long)\n        movie_tensor = torch.tensor([movie_id], dtype=torch.long)\n        \n        user_onehot = torch.zeros(1, n_users)\n        user_onehot[0, user_id] = 1.0\n        \n        movie_onehot = torch.zeros(1, n_movies)\n        movie_onehot[0, movie_id] = 1.0\n        \n        # Get predictions from the model\n        model_output = model(user_onehot, movie_onehot)\n        \n        # Store the movie ID and its predicted rating\n        movie_ratings.append((movie_id, model_output.item()))  # Assuming model_output contains the predicted rating\n    \n    # Sort the movie ratings based on predicted ratings\n    movie_ratings.sort(key=lambda x: x[1], reverse=True)\n    \n    # Check if the highest rated item is among the top 10 recommendations\n    top_10_recommendations = [movie_id for movie_id, _ in movie_ratings[:10]]\n    if user_id in top20_users:\n        if highest_rated_movie_id in top_10_recommendations:\n            hits_count_top20 += 1\n        total_users_top20 += 1\n    elif user_id in bottom20_users:\n        if highest_rated_movie_id in top_10_recommendations:\n            hits_count_bottom20 += 1\n        total_users_bottom20 += 1\n\n# Calculate hit rate for top 20 and bottom 20 users\nhit_rate_top20 = hits_count_top20 / total_users_top20 if total_users_top20 > 0 else 0\nhit_rate_bottom20 = hits_count_bottom20 / total_users_bottom20 if total_users_bottom20 > 0 else 0\n\nprint(\"Hit rate for top 20 frequent users:\", hit_rate_top20)\nprint(\"Hit rate for bottom 20 frequent users:\", hit_rate_bottom20)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-21T06:57:04.977211Z","iopub.execute_input":"2024-02-21T06:57:04.977627Z","iopub.status.idle":"2024-02-21T06:58:40.066331Z","shell.execute_reply.started":"2024-02-21T06:57:04.977592Z","shell.execute_reply":"2024-02-21T06:58:40.065040Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"Hit rate for top 20 frequent users: 0.7368421052631579\nHit rate for bottom 20 frequent users: 0.65\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\n\n# Initialize variables to track NDCG@10\nndcg_sum = 0\nnum_users = 0\n\n# Iterate over each user\nfor user_id in df['userId'].unique():\n    if user_id == 610:\n        continue \n    \n    # Get movies rated by the user\n    rated_movies = df[df['userId'] == user_id]\n    \n    # Sample 100 unrated movie IDs if available\n    unrated_movie_ids = df[~df['movieId'].isin(rated_movies['movieId'])]['movieId'].unique()\n    sampled_movie_ids = np.random.choice(unrated_movie_ids, size=min(100, len(unrated_movie_ids)), replace=False)\n    \n    # Append the highest rated movie for the user\n    highest_rated_movie_id = rated_movies.nlargest(1, 'rating')['movieId'].values[0]\n    sampled_movie_ids = np.append(sampled_movie_ids, highest_rated_movie_id)\n    \n    # Initialize list to store movie ratings\n    movie_ratings = []\n    \n    # Iterate over each sampled movie\n    for movie_id in sampled_movie_ids:\n        # One-hot encode user and movie\n        user_tensor = torch.tensor([user_id], dtype=torch.long)\n        movie_tensor = torch.tensor([movie_id], dtype=torch.long)\n        \n        user_onehot = torch.zeros(1, n_users)\n        user_onehot[0, user_id] = 1.0\n        \n        movie_onehot = torch.zeros(1, n_movies)\n        movie_onehot[0, movie_id] = 1.0\n        \n        # Get predictions from the model\n        model_output = model(user_onehot, movie_onehot)\n        \n        # Store the movie ID and its predicted rating\n        movie_ratings.append((movie_id, model_output.item()))  # Assuming model_output contains the predicted rating\n    \n    # Sort the movie ratings based on predicted ratings\n    movie_ratings.sort(key=lambda x: x[1], reverse=True)\n    \n    # Get the index of the highest rated item for the user\n    highest_rated_item_index = np.where(sampled_movie_ids == highest_rated_movie_id)[0][0]\n    \n    # Compute DCG@10 for the user\n    dcg = 0\n    for rank, (movie_id, _) in enumerate(movie_ratings[:10], start=1):\n        relevance = 1 if np.where(sampled_movie_ids == movie_id)[0][0] == highest_rated_item_index else 0\n        dcg += (2 ** relevance - 1) / np.log2(rank + 1)\n    \n    # Compute ideal DCG@10 for the user\n    ideal_dcg = sum((2 ** 1 - 1) / np.log2(rank + 1) for rank in range(1, min(11, len(rated_movies) + 1)))\n    \n    # Accumulate NDCG@10\n    if ideal_dcg > 0:\n        ndcg_sum += dcg / ideal_dcg\n        num_users += 1\n\n# Calculate average NDCG@10\nndcg_at_10 = ndcg_sum / num_users if num_users > 0 else 0\nprint(\"Average NDCG@10:\", ndcg_at_10)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-21T06:58:40.068484Z","iopub.execute_input":"2024-02-21T06:58:40.069251Z","iopub.status.idle":"2024-02-21T07:00:10.359953Z","shell.execute_reply.started":"2024-02-21T06:58:40.069213Z","shell.execute_reply":"2024-02-21T07:00:10.358767Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"Average NDCG@10: 0.12124734452122758\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\n\n# Initialize variables to track NDCG@10 and the number of users\nndcg_sum = 0\nnum_users = 0\n\n# Iterate over each user\nfor user_id in df['userId'].unique():\n    if user_id == 610:\n        continue \n    \n    # Get movies rated by the user\n    rated_movies = df[df['userId'] == user_id]\n    \n    # Sample 100 unrated movie IDs if available\n    unrated_movie_ids = df[~df['movieId'].isin(rated_movies['movieId'])]['movieId'].unique()\n    sampled_movie_ids = np.random.choice(unrated_movie_ids, size=min(100, len(unrated_movie_ids)), replace=False)\n    \n    # Append the highest rated movie for the user\n    highest_rated_movie_id = rated_movies.nlargest(1, 'rating')['movieId'].values[0]\n    sampled_movie_ids = np.append(sampled_movie_ids, highest_rated_movie_id)\n    \n    # Initialize list to store movie ratings\n    movie_ratings = []\n    \n    # Iterate over each sampled movie\n    for movie_id in sampled_movie_ids:\n        # One-hot encode user and movie\n        user_tensor = torch.tensor([user_id], dtype=torch.long)\n        movie_tensor = torch.tensor([movie_id], dtype=torch.long)\n        \n        user_onehot = torch.zeros(1, n_users)\n        user_onehot[0, user_id] = 1.0\n        \n        movie_onehot = torch.zeros(1, n_movies)\n        movie_onehot[0, movie_id] = 1.0\n        \n        # Get predictions from the model\n        model_output = model(user_onehot, movie_onehot)\n        \n        # Store the movie ID and its predicted rating\n        movie_ratings.append((movie_id, model_output.item()))  # Assuming model_output contains the predicted rating\n    \n    # Sort the movie ratings based on predicted ratings\n    movie_ratings.sort(key=lambda x: x[1], reverse=True)\n    \n    # Check if the test movie is in the top 10 recommendations\n    if highest_rated_movie_id in [movie_id for movie_id, _ in movie_ratings[:10]]:\n        num_users += 1  # Increment the number of users\n    \n        # Get the index of the highest rated item for the user\n        highest_rated_item_index = np.where(sampled_movie_ids == highest_rated_movie_id)[0][0]\n        \n        # Compute DCG@10 for the user\n        dcg = 0\n        for rank, (movie_id, _) in enumerate(movie_ratings[:10], start=1):\n            relevance = 1 if np.where(sampled_movie_ids == movie_id)[0][0] == highest_rated_item_index else 0\n            dcg += (2 ** relevance - 1) / np.log2(rank + 1)\n        \n        # Compute ideal DCG@10 for the user\n        ideal_dcg = sum((2 ** 1 - 1) / np.log2(rank + 1) for rank in range(1, min(11, len(rated_movies) + 1)))\n        \n        # Accumulate NDCG@10\n        if ideal_dcg > 0:\n            ndcg_sum += dcg / ideal_dcg\n\n# Calculate average NDCG@10\nndcg_at_10 = ndcg_sum / num_users if num_users > 0 else 0\nprint(\"NDCG@10:\", ndcg_at_10)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-21T07:00:10.362002Z","iopub.execute_input":"2024-02-21T07:00:10.362492Z","iopub.status.idle":"2024-02-21T07:01:45.366629Z","shell.execute_reply.started":"2024-02-21T07:00:10.362435Z","shell.execute_reply":"2024-02-21T07:01:45.365709Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stdout","text":"NDCG@10: 0.14939698707367843\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\n\n# Get the number of ratings provided by each user\nuser_rating_counts = df['userId'].value_counts()\n\n# Sort users based on the number of ratings they have provided\nsorted_users = user_rating_counts.index.tolist()\n\n# Get the top 20 and bottom 20 frequent users\ntop_20_users = sorted_users[:20]\nbottom_20_users = sorted_users[-20:]\n\n# Function to calculate NDCG@10 for a given set of users\ndef calculate_ndcg(users):\n    # Initialize variables to track NDCG@10 and the number of users\n    ndcg_sum = 0\n    num_users = 0\n\n    # Iterate over each user\n    for user_id in users:\n        if user_id == 610:\n            continue \n        # Get movies rated by the user\n        rated_movies = df[df['userId'] == user_id]\n\n        # Sample 100 unrated movie IDs if available\n        unrated_movie_ids = df[~df['movieId'].isin(rated_movies['movieId'])]['movieId'].unique()\n        sampled_movie_ids = np.random.choice(unrated_movie_ids, size=min(100, len(unrated_movie_ids)), replace=False)\n\n        # Append the highest rated movie for the user\n        highest_rated_movie_id = rated_movies.nlargest(1, 'rating')['movieId'].values[0]\n        sampled_movie_ids = np.append(sampled_movie_ids, highest_rated_movie_id)\n\n        # Initialize list to store movie ratings\n        movie_ratings = []\n\n        # Iterate over each sampled movie\n        for movie_id in sampled_movie_ids:\n            # One-hot encode user and movie (assuming n_users and n_movies are defined)\n            user_tensor = torch.tensor([user_id], dtype=torch.long)\n            movie_tensor = torch.tensor([movie_id], dtype=torch.long)\n            user_onehot = torch.zeros(1, n_users)\n            user_onehot[0, user_id] = 1.0\n            movie_onehot = torch.zeros(1, n_movies)\n            movie_onehot[0, movie_id] = 1.0\n\n            # Get predictions from the model\n            model_output = model(user_onehot, movie_onehot)\n\n            # Store the movie ID and its predicted rating\n            movie_ratings.append((movie_id, model_output.item()))\n\n        # Sort the movie ratings based on predicted ratings\n        movie_ratings.sort(key=lambda x: x[1], reverse=True)\n\n        # Check if the test movie is in the top 10 recommendations\n        if highest_rated_movie_id in [movie_id for movie_id, _ in movie_ratings[:10]]:\n            num_users += 1  # Increment the number of users\n\n            # Get the index of the highest rated item for the user\n            highest_rated_item_index = np.where(sampled_movie_ids == highest_rated_movie_id)[0][0]\n\n            # Compute DCG@10 for the user\n            dcg = 0\n            for rank, (movie_id, _) in enumerate(movie_ratings[:10], start=1):\n                relevance = 1 if np.where(sampled_movie_ids == movie_id)[0][0] == highest_rated_item_index else 0\n                dcg += (2 ** relevance - 1) / np.log2(rank + 1)\n\n            # Compute ideal DCG@10 for the user\n            ideal_dcg = sum((2 ** 1 - 1) / np.log2(rank + 1) for rank in range(1, min(11, len(rated_movies) + 1)))\n\n            # Accumulate NDCG@10\n            if ideal_dcg > 0:\n                ndcg_sum += dcg / ideal_dcg\n\n    # Calculate average NDCG@10\n    average_ndcg_at_10 = ndcg_sum / num_users if num_users > 0 else 0\n    return average_ndcg_at_10\n\n# Calculate NDCG@10 for the top 20 frequent users\nndcg_top_20 = calculate_ndcg(top_20_users)\nprint(\"NDCG@10 for top 20 frequent users:\", ndcg_top_20)\n\n# Calculate NDCG@10 for the bottom 20 frequent users\nndcg_bottom_20 = calculate_ndcg(bottom_20_users)\nprint(\"NDCG@10 for bottom 20 frequent users:\", ndcg_bottom_20)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-21T07:01:45.368672Z","iopub.execute_input":"2024-02-21T07:01:45.369417Z","iopub.status.idle":"2024-02-21T07:01:52.996325Z","shell.execute_reply.started":"2024-02-21T07:01:45.369370Z","shell.execute_reply":"2024-02-21T07:01:52.994907Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"NDCG@10 for top 20 frequent users: 0.13667566415571658\nNDCG@10 for bottom 20 frequent users: 0.17165347424327637\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\n\n# Initialize variables to track hits, DCG, and IDCG\nhits_count = 0\ndcg_sum = 0\nidcg_sum = 0\n\n# Iterate over each user\nfor user_id in df['userId'].unique():\n    if user_id == 610:\n        continue \n    # Get movies rated by the user\n    rated_movies = df[df['userId'] == user_id]\n    \n    # Sample 100 unrated movie IDs if available\n    unrated_movie_ids = df[~df['movieId'].isin(rated_movies['movieId'])]['movieId'].unique()\n    sampled_movie_ids = np.random.choice(unrated_movie_ids, size=min(100, len(unrated_movie_ids)), replace=False)\n    \n    # Append the highest rated movie for the user\n    highest_rated_movie_id = rated_movies.nlargest(1, 'rating')['movieId'].values[0]\n    sampled_movie_ids = np.append(sampled_movie_ids, highest_rated_movie_id)\n    \n    # Initialize list to store movie ratings\n    movie_ratings = []\n    \n    # Iterate over each sampled movie\n    for movie_id in sampled_movie_ids:\n        # One-hot encode user and movie\n        user_tensor = torch.tensor([user_id], dtype=torch.long)\n        movie_tensor = torch.tensor([movie_id], dtype=torch.long)\n        \n        user_onehot = torch.zeros(1, n_users)\n        user_onehot[0, user_id] = 1.0\n        \n        movie_onehot = torch.zeros(1, n_movies)\n        movie_onehot[0, movie_id] = 1.0\n        \n        # Get predictions from the model\n        model_output = model(user_onehot, movie_onehot)\n        \n        # Store the movie ID and its predicted rating\n        movie_ratings.append((movie_id, model_output.item()))  # Assuming model_output contains the predicted rating\n    \n    # Sort the movie ratings based on predicted ratings\n    movie_ratings.sort(key=lambda x: x[1], reverse=True)\n    \n    # Get the index of the highest rated item for the user\n    highest_rated_item_index = np.where(sampled_movie_ids == highest_rated_movie_id)[0][0]\n    \n    # Compute DCG@10 for the user\n    dcg = 0\n    for rank, (movie_id, _) in enumerate(movie_ratings[:10], start=1):\n        relevance = 1 if np.where(sampled_movie_ids == movie_id)[0][0] == highest_rated_item_index else 0\n        dcg += (2 ** relevance - 1) / np.log2(rank + 1)\n    \n    # Compute ideal DCG@10 for the user\n    ideal_dcg = sum((2 ** 1 - 1) / np.log2(rank + 1) for rank in range(1, min(11, len(rated_movies) + 1)))\n    \n    # Update sums\n    hits_count += 1 if highest_rated_movie_id in [movie_id for movie_id, _ in movie_ratings[:10]] else 0\n    dcg_sum += dcg\n    idcg_sum += ideal_dcg\n\n# Calculate NDCG@10\nndcg = dcg_sum / idcg_sum if idcg_sum > 0 else 0\nhit_rate = hits_count / total_users if total_users > 0 else 0\n\n#print(\"Hit rate:\", hit_rate)\nprint(\"NDCG@10:\", ndcg)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-21T07:01:52.998288Z","iopub.execute_input":"2024-02-21T07:01:52.998645Z","iopub.status.idle":"2024-02-21T07:03:33.505148Z","shell.execute_reply.started":"2024-02-21T07:01:52.998615Z","shell.execute_reply":"2024-02-21T07:03:33.503812Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stdout","text":"NDCG@10: 0.12114027355114974\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\n\n# Initialize variables to track DCG and IDCG\ndcg_sum = 0\nidcg_sum = 0\n\n# Iterate over each user\nfor user_id in df['userId'].unique():\n    if user_id == 610:\n        continue \n    # Get movies rated by the user\n    rated_movies = df[df['userId'] == user_id]\n    \n    # Sample 100 unrated movie IDs if available\n    unrated_movie_ids = df[~df['movieId'].isin(rated_movies['movieId'])]['movieId'].unique()\n    sampled_movie_ids = np.random.choice(unrated_movie_ids, size=min(100, len(unrated_movie_ids)), replace=False)\n    \n    # Append the highest rated movie for the user\n    highest_rated_movie_id = rated_movies.nlargest(1, 'rating')['movieId'].values[0]\n    sampled_movie_ids = np.append(sampled_movie_ids, highest_rated_movie_id)\n    \n    # Initialize list to store movie ratings\n    movie_ratings = []\n    \n    # Iterate over each sampled movie\n    for movie_id in sampled_movie_ids:\n        # One-hot encode user and movie\n        user_tensor = torch.tensor([user_id], dtype=torch.long)\n        movie_tensor = torch.tensor([movie_id], dtype=torch.long)\n        \n        user_onehot = torch.zeros(1, n_users)\n        user_onehot[0, user_id] = 1.0\n        \n        movie_onehot = torch.zeros(1, n_movies)\n        movie_onehot[0, movie_id] = 1.0\n        \n        # Get predictions from the model\n        model_output = model(user_onehot, movie_onehot)\n        \n        # Store the movie ID and its predicted rating\n        movie_ratings.append((movie_id, model_output.item()))  # Assuming model_output contains the predicted rating\n    \n    # Sort the movie ratings based on predicted ratings\n    movie_ratings.sort(key=lambda x: x[1], reverse=True)\n    \n    # Get the relevance scores (ratings) for the recommended movies\n    relevance_scores = [rated_movies[rated_movies['movieId'] == movie_id]['rating'].values[0] if movie_id in rated_movies['movieId'].values else 0 for movie_id, _ in movie_ratings[:10]]\n    \n    # Calculate DCG\n    dcg = np.sum(relevance_scores / np.log2(np.arange(2, len(relevance_scores) + 2)))\n    \n    # Calculate IDCG\n    ideal_relevance_scores = sorted(rated_movies['rating'].values, reverse=True)[:min(10, len(rated_movies))]\n    idcg = np.sum(ideal_relevance_scores / np.log2(np.arange(2, len(ideal_relevance_scores) + 2)))\n    \n    # Update sums\n    dcg_sum += dcg\n    idcg_sum += idcg\n\n# Calculate NDCG@10\n# Calculate NDCG@10\nndcg = (dcg_sum * 10) / idcg_sum if idcg_sum > 0 else 0\nprint(\"NDCG@10:\", ndcg)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-02-21T07:03:33.507102Z","iopub.execute_input":"2024-02-21T07:03:33.507582Z","iopub.status.idle":"2024-02-21T07:05:13.170346Z","shell.execute_reply.started":"2024-02-21T07:03:33.507543Z","shell.execute_reply":"2024-02-21T07:05:13.168782Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stdout","text":"NDCG@10: 1.2651482456259044\n","output_type":"stream"}]},{"cell_type":"code","source":"# Set the model to evaluation mode\nmodel.eval()\n\n# Initialize variables to track hits\nhits_count = 0\ntotal_users = 0\n\n# Specify the user for evaluation\nuser_id = 2  # Assuming the user ID is 123\n\n# Get movies rated by the user\nrated_movies = df[df['userId'] == user_id]\n\n# Sample 100 unrated movie IDs if available\nunrated_movie_ids = df[~df['movieId'].isin(rated_movies['movieId'])]['movieId'].unique()\nsampled_movie_ids = np.random.choice(unrated_movie_ids, size=min(100, len(unrated_movie_ids)), replace=False)\n\n# Append the highest rated movie for the user\nhighest_rated_movie_id = rated_movies.nlargest(1, 'rating')['movieId'].values[0]\nsampled_movie_ids = np.append(sampled_movie_ids, highest_rated_movie_id)\n\n# Initialize list to store movie ratings\nmovie_ratings = []\n\n# Iterate over each sampled movie\nfor movie_id in sampled_movie_ids:\n    # One-hot encode user and movie\n    user_tensor = torch.tensor([user_id], dtype=torch.long)\n    movie_tensor = torch.tensor([movie_id], dtype=torch.long)\n    \n    user_onehot = torch.zeros(1, n_users)\n    user_onehot[0, user_id] = 1.0\n    \n    movie_onehot = torch.zeros(1, n_movies)\n    movie_onehot[0, movie_id] = 1.0\n    \n    # Get predictions from the model\n    model_output = model(user_onehot, movie_onehot)\n    \n    # Store the movie ID and its predicted rating\n    movie_ratings.append((movie_id, model_output.item()))  # Assuming model_output contains the predicted rating\n\n# Sort the movie ratings based on predicted ratings\nmovie_ratings.sort(key=lambda x: x[1], reverse=True)\n\n# Print the test movie ID\nprint(\"Test Movie ID:\", highest_rated_movie_id)\n\n# Print the movie indices of top 10 recommendations\ntop_10_recommendations = [movie_id for movie_id, _ in movie_ratings[:10]]\nprint(\"Top 10 Recommended Movie IDs:\", top_10_recommendations)\n\n# Map the indices back to original movieIds\ntop_10_original_movieIds = [sampled_movie_ids[np.where(sampled_movie_ids == movie_id)[0][0]] for movie_id in top_10_recommendations]\nprint(\"Top 10 Recommended Original Movie IDs:\", top_10_original_movieIds)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-21T07:05:13.172772Z","iopub.execute_input":"2024-02-21T07:05:13.173313Z","iopub.status.idle":"2024-02-21T07:05:13.357637Z","shell.execute_reply.started":"2024-02-21T07:05:13.173264Z","shell.execute_reply":"2024-02-21T07:05:13.356147Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stdout","text":"Test Movie ID: 60756\nTop 10 Recommended Movie IDs: [55442, 3476, 39444, 3811, 60756, 128360, 1952, 3019, 1594, 2971]\nTop 10 Recommended Original Movie IDs: [55442, 3476, 39444, 3811, 60756, 128360, 1952, 3019, 1594, 2971]\n","output_type":"stream"}]},{"cell_type":"code","source":"# Check if the highest rated item is among the top 10 recommendations for this user\nif highest_rated_movie_id in top_10_original_movieIds:\n    print(\"Hit: Highest rated movie is among the top 10 recommended movies for User\", user_id)\n    hits_count += 1\nelse:\n    print(\"Miss: Highest rated movie is not among the top 10 recommended movies for User\", user_id)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-21T07:05:13.359832Z","iopub.execute_input":"2024-02-21T07:05:13.360392Z","iopub.status.idle":"2024-02-21T07:05:13.368311Z","shell.execute_reply.started":"2024-02-21T07:05:13.360340Z","shell.execute_reply":"2024-02-21T07:05:13.366730Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stdout","text":"Hit: Highest rated movie is among the top 10 recommended movies for User 2\n","output_type":"stream"}]},{"cell_type":"code","source":"# Choose the first user ID (assuming user IDs start from 1)\nfirst_user_id = 2\n\n# Filter the training set for the first user\ntraining_ratings_first_user = df_train[df_train['userId'] == first_user_id]\n\n# Filter the validation set for the first user\nvalidation_ratings_first_user = df_valid[df_valid['userId'] == first_user_id]\n\n# Print information for the training set\nprint(f\"Training Set - User {first_user_id} Ratings:\")\nprint(training_ratings_first_user[['movieId', 'rating']])\n\n# Print information for the validation set\nprint(f\"\\nValidation Set - User {first_user_id} Ratings:\")\nprint(validation_ratings_first_user[['movieId', 'rating']])\n\n# Check if movie ID 100 is present in the training set for the first user\nis_movie_100_in_training = 100 in training_ratings_first_user['movieId'].values\nprint(f\"Is Movie ID 100 present in the training set for User {first_user_id}? {is_movie_100_in_training}\")\n\n# Check if movie ID 100 is present in the validation set for the first user\nis_movie_100_in_validation = 100 in validation_ratings_first_user['movieId'].values\nprint(f\"Is Movie ID 100 present in the validation set for User {first_user_id}? {is_movie_100_in_validation}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-02-21T07:05:13.370908Z","iopub.execute_input":"2024-02-21T07:05:13.371862Z","iopub.status.idle":"2024-02-21T07:05:13.395832Z","shell.execute_reply.started":"2024-02-21T07:05:13.371810Z","shell.execute_reply":"2024-02-21T07:05:13.394646Z"},"trusted":true},"execution_count":49,"outputs":[{"name":"stdout","text":"Training Set - User 2 Ratings:\n     movieId  rating\n257   114060     2.0\n260   131724     5.0\n239    48516     4.0\n253    99114     3.5\n246    79132     4.0\n238    46970     4.0\n242    68157     4.5\n241    60756     5.0\n240    58559     4.5\n250    89774     5.0\n237     8798     3.5\n249    86345     4.0\n254   106782     5.0\n244    74458     4.0\n252    91658     2.5\n258   115713     3.5\n256   112552     4.0\n234     1704     4.5\n247    80489     4.5\n236     6874     4.0\n251    91529     3.5\n232      318     3.0\n248    80906     5.0\n255   109487     3.0\n259   122882     5.0\n235     3578     4.0\n\nValidation Set - User 2 Ratings:\n     movieId  rating\n243    71535     3.0\n233      333     4.0\n245    77455     3.0\nIs Movie ID 100 present in the training set for User 2? False\nIs Movie ID 100 present in the validation set for User 2? False\n","output_type":"stream"}]},{"cell_type":"code","source":"# Set the model to evaluation mode\nmodel.eval()\n\n# Initialize variables to track hits\nhits_count = 0\ntotal_users = 0\n\n# Iterate over each user\nfor user_id in df['userId'].unique():\n    if user_id == 610:\n        continue \n    # Get movies rated by the user\n    rated_movies = df[df['userId'] == user_id]\n    \n    # Check if the highest rated movie for the user is 5\n    if rated_movies['rating'].max() == 5:\n        # Sample 100 unrated movie IDs if available\n        unrated_movie_ids = df[~df['movieId'].isin(rated_movies['movieId'])]['movieId'].unique()\n        sampled_movie_ids = np.random.choice(unrated_movie_ids, size=min(100, len(unrated_movie_ids)), replace=False)\n        \n        # Append the highest rated movie for the user\n        highest_rated_movie_id = rated_movies.nlargest(1, 'rating')['movieId'].values[0]\n        sampled_movie_ids = np.append(sampled_movie_ids, highest_rated_movie_id)\n        \n        # Initialize list to store movie ratings\n        movie_ratings = []\n        \n        # Iterate over each sampled movie\n        for movie_id in sampled_movie_ids:\n            # One-hot encode user and movie\n            user_tensor = torch.tensor([user_id], dtype=torch.long)\n            movie_tensor = torch.tensor([movie_id], dtype=torch.long)\n            \n            user_onehot = torch.zeros(1, n_users)\n            user_onehot[0, user_id] = 1.0\n            \n            movie_onehot = torch.zeros(1, n_movies)\n            movie_onehot[0, movie_id] = 1.0\n            \n            # Get predictions from the model\n            model_output = model(user_onehot, movie_onehot)\n            \n            # Store the movie ID and its predicted rating\n            movie_ratings.append((movie_id, model_output.item()))  # Assuming model_output contains the predicted rating\n        \n        # Sort the movie ratings based on predicted ratings\n        movie_ratings.sort(key=lambda x: x[1], reverse=True)\n        \n        # Check if the highest rated item is among the top 10 recommendations\n        top_10_recommendations = [movie_id for movie_id, _ in movie_ratings[:5]]\n        if highest_rated_movie_id in top_10_recommendations:\n            hits_count += 1\n        \n        total_users += 1\n\n# Calculate hit rate\nhit_rate = hits_count / total_users if total_users > 0 else 0\nprint(\"Hit rate:\", hit_rate)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-21T07:52:31.835139Z","iopub.execute_input":"2024-02-21T07:52:31.835621Z","iopub.status.idle":"2024-02-21T07:54:06.454804Z","shell.execute_reply.started":"2024-02-21T07:52:31.835583Z","shell.execute_reply":"2024-02-21T07:54:06.452244Z"},"trusted":true},"execution_count":72,"outputs":[{"name":"stdout","text":"Hit rate: 0.6713286713286714\n","output_type":"stream"}]},{"cell_type":"code","source":"# Set the model to evaluation mode\nmodel.eval()\n\n# Initialize variables to track hits\nhits_count_top20 = 0\nhits_count_bottom20 = 0\ntotal_users_top20 = 0\ntotal_users_bottom20 = 0\n\n# Get the number of ratings provided by each user\nuser_rating_counts = df['userId'].value_counts()\n\n# Sort users based on the number of ratings they have provided\nsorted_users = user_rating_counts.index.tolist()\n\n# Select the top 20 and bottom 20 frequent users\ntop20_users = sorted_users[:20]\nbottom20_users = sorted_users[-20:]\n\n# Iterate over each user\nfor user_id in df['userId'].unique():\n    # Skip user 610\n    if user_id == 610:\n        continue\n    \n    # Get movies rated by the user\n    rated_movies = df[df['userId'] == user_id]\n    \n    # Sample 100 unrated movie IDs if available\n    unrated_movie_ids = df[~df['movieId'].isin(rated_movies['movieId'])]['movieId'].unique()\n    sampled_movie_ids = np.random.choice(unrated_movie_ids, size=min(100, len(unrated_movie_ids)), replace=False)\n    \n    # Append the highest rated movie for the user\n    highest_rated_movie_id = rated_movies.nlargest(1, 'rating')['movieId'].values[0]\n    sampled_movie_ids = np.append(sampled_movie_ids, highest_rated_movie_id)\n    \n    # Initialize list to store movie ratings\n    movie_ratings = []\n    \n    # Iterate over each sampled movie\n    for movie_id in sampled_movie_ids:\n        # One-hot encode user and movie\n        user_tensor = torch.tensor([user_id], dtype=torch.long)\n        movie_tensor = torch.tensor([movie_id], dtype=torch.long)\n        \n        user_onehot = torch.zeros(1, n_users)\n        user_onehot[0, user_id] = 1.0\n        \n        movie_onehot = torch.zeros(1, n_movies)\n        movie_onehot[0, movie_id] = 1.0\n        \n        # Get predictions from the model\n        model_output = model(user_onehot, movie_onehot)\n        \n        # Store the movie ID and its predicted rating\n        movie_ratings.append((movie_id, model_output.item()))  # Assuming model_output contains the predicted rating\n    \n    # Sort the movie ratings based on predicted ratings\n    movie_ratings.sort(key=lambda x: x[1], reverse=True)\n    \n    # Check if the highest rated item is among the top 10 recommendations\n    top_10_recommendations = [movie_id for movie_id, _ in movie_ratings[:5]]\n    if user_id in top20_users:\n        if highest_rated_movie_id in top_10_recommendations:\n            hits_count_top20 += 1\n        total_users_top20 += 1\n    elif user_id in bottom20_users:\n        if highest_rated_movie_id in top_10_recommendations:\n            hits_count_bottom20 += 1\n        total_users_bottom20 += 1\n\n# Calculate hit rate for top 20 and bottom 20 users\nhit_rate_top20 = hits_count_top20 / total_users_top20 if total_users_top20 > 0 else 0\nhit_rate_bottom20 = hits_count_bottom20 / total_users_bottom20 if total_users_bottom20 > 0 else 0\n\nprint(\"Hit rate for top 20 frequent users:\", hit_rate_top20)\nprint(\"Hit rate for bottom 20 frequent users:\", hit_rate_bottom20)","metadata":{"execution":{"iopub.status.busy":"2024-02-21T07:54:06.457296Z","iopub.execute_input":"2024-02-21T07:54:06.458354Z","iopub.status.idle":"2024-02-21T07:55:51.043987Z","shell.execute_reply.started":"2024-02-21T07:54:06.458299Z","shell.execute_reply":"2024-02-21T07:55:51.043017Z"},"trusted":true},"execution_count":73,"outputs":[{"name":"stdout","text":"Hit rate for top 20 frequent users: 0.6842105263157895\nHit rate for bottom 20 frequent users: 0.6\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}