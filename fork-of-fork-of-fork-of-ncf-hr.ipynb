{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":6356268,"sourceType":"datasetVersion","datasetId":3660994}],"dockerImageVersionId":30626,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn import model_selection, metrics, preprocessing\nimport torch\nimport torch.nn as nn\nimport matplotlib.pyplot as plt \nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn.functional as F\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-02-23T08:57:45.948385Z","iopub.execute_input":"2024-02-23T08:57:45.948774Z","iopub.status.idle":"2024-02-23T08:57:49.078108Z","shell.execute_reply.started":"2024-02-23T08:57:45.948743Z","shell.execute_reply":"2024-02-23T08:57:49.076840Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/movielens-9000-movies-dataset/ml-latest-small/ratings.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-02-23T08:57:49.079691Z","iopub.execute_input":"2024-02-23T08:57:49.080148Z","iopub.status.idle":"2024-02-23T08:57:49.204537Z","shell.execute_reply.started":"2024-02-23T08:57:49.080122Z","shell.execute_reply":"2024-02-23T08:57:49.203730Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"df.info() # basically show schema","metadata":{"execution":{"iopub.status.busy":"2024-02-23T08:57:49.205898Z","iopub.execute_input":"2024-02-23T08:57:49.206196Z","iopub.status.idle":"2024-02-23T08:57:49.235202Z","shell.execute_reply.started":"2024-02-23T08:57:49.206158Z","shell.execute_reply":"2024-02-23T08:57:49.233722Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 100836 entries, 0 to 100835\nData columns (total 4 columns):\n #   Column     Non-Null Count   Dtype  \n---  ------     --------------   -----  \n 0   userId     100836 non-null  int64  \n 1   movieId    100836 non-null  int64  \n 2   rating     100836 non-null  float64\n 3   timestamp  100836 non-null  int64  \ndtypes: float64(1), int64(3)\nmemory usage: 3.1 MB\n","output_type":"stream"}]},{"cell_type":"code","source":"df.userId.nunique()","metadata":{"execution":{"iopub.status.busy":"2024-02-23T08:57:49.237738Z","iopub.execute_input":"2024-02-23T08:57:49.238206Z","iopub.status.idle":"2024-02-23T08:57:49.246390Z","shell.execute_reply.started":"2024-02-23T08:57:49.238183Z","shell.execute_reply":"2024-02-23T08:57:49.245646Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"610"},"metadata":{}}]},{"cell_type":"code","source":"df.movieId.nunique()","metadata":{"execution":{"iopub.status.busy":"2024-02-23T08:57:49.247571Z","iopub.execute_input":"2024-02-23T08:57:49.247834Z","iopub.status.idle":"2024-02-23T08:57:49.254327Z","shell.execute_reply.started":"2024-02-23T08:57:49.247813Z","shell.execute_reply":"2024-02-23T08:57:49.253465Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"9724"},"metadata":{}}]},{"cell_type":"code","source":"df.rating.value_counts() #check value distribution","metadata":{"execution":{"iopub.status.busy":"2024-02-23T08:57:49.255501Z","iopub.execute_input":"2024-02-23T08:57:49.255723Z","iopub.status.idle":"2024-02-23T08:57:49.266094Z","shell.execute_reply.started":"2024-02-23T08:57:49.255702Z","shell.execute_reply":"2024-02-23T08:57:49.265221Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"rating\n4.0    26818\n3.0    20047\n5.0    13211\n3.5    13136\n4.5     8551\n2.0     7551\n2.5     5550\n1.0     2811\n1.5     1791\n0.5     1370\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2024-02-23T08:57:49.267308Z","iopub.execute_input":"2024-02-23T08:57:49.267617Z","iopub.status.idle":"2024-02-23T08:57:49.275498Z","shell.execute_reply.started":"2024-02-23T08:57:49.267595Z","shell.execute_reply":"2024-02-23T08:57:49.274689Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"(100836, 4)"},"metadata":{}}]},{"cell_type":"code","source":"# Get the number of unique users and movies\nn_users = df.userId.nunique()\nn_movies = df.movieId.max() + 1\n\n","metadata":{"execution":{"iopub.status.busy":"2024-02-23T08:57:49.278402Z","iopub.execute_input":"2024-02-23T08:57:49.278699Z","iopub.status.idle":"2024-02-23T08:57:49.284373Z","shell.execute_reply.started":"2024-02-23T08:57:49.278676Z","shell.execute_reply":"2024-02-23T08:57:49.283446Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"class MovieDataset:\n    def __init__(self, df, n_users, n_movies):\n        self.users = df.userId.values\n        self.movies = df.movieId.values\n        self.ratings = df.rating.values\n        self.n_users = n_users\n        self.n_movies = n_movies\n\n    def __len__(self):\n        return len(self.users)\n\n    def __getitem__(self, item):\n        user = self.users[item]\n        movie = self.movies[item]\n        rating = self.ratings[item]\n\n        # Check and correct user index\n        if user >= self.n_users:\n            user = self.n_users - 1\n\n        # One-hot encode user and movie IDs\n        user_onehot = torch.zeros(self.n_users)\n        user_onehot[user] = 1.0\n\n        movie_onehot = torch.zeros(self.n_movies)\n        movie_onehot[movie] = 1.0\n\n        return {\n            \"users_onehot\": user_onehot,\n            \"movies_onehot\": movie_onehot,\n            \"ratings\": torch.tensor(rating, dtype=torch.float32),\n        }\n\n# Create an instance of MovieDataset with your data\ndataset = MovieDataset(df, n_users, n_movies)\n\n# Check the max indices\nprint(\"Max user index:\", dataset.users.max())\nprint(\"Max movie index:\", dataset.movies.max())","metadata":{"execution":{"iopub.status.busy":"2024-02-23T08:57:49.285596Z","iopub.execute_input":"2024-02-23T08:57:49.285842Z","iopub.status.idle":"2024-02-23T08:57:49.294173Z","shell.execute_reply.started":"2024-02-23T08:57:49.285821Z","shell.execute_reply":"2024-02-23T08:57:49.293291Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Max user index: 610\nMax movie index: 193609\n","output_type":"stream"}]},{"cell_type":"code","source":"class RecSysModel(nn.Module):\n    def __init__(self, n_users, n_movies, emb_size=32):\n        super().__init__()\n        self.user_embed = nn.Linear(n_users, emb_size, bias=False)\n        self.movie_embed = nn.Linear(n_movies, emb_size, bias=False)\n        self.hidden1 = nn.Linear(emb_size * 2, 32)\n        self.hidden2 = nn.Linear(32, 16)\n        self.hidden3 = nn.Linear(16, 8)\n        self.out = nn.Linear(8, 1)\n\n    def forward(self, users_onehot, movies_onehot):\n        user_embeds = self.user_embed(users_onehot)\n        movie_embeds = self.movie_embed(movies_onehot)\n        user_embeds = user_embeds.view(-1, user_embeds.size(1))\n        movie_embeds = movie_embeds.view(-1, movie_embeds.size(1))\n        embedding = torch.cat([user_embeds, movie_embeds], dim=1)\n        embedding = F.relu(self.hidden1(embedding))\n        embedding = F.relu(self.hidden2(embedding))\n        embedding = F.relu(self.hidden3(embedding))\n        output = self.out(embedding)\n        return output\n\n    def predict_ratings(self, users_onehot, movies_onehot):\n        with torch.no_grad():\n            output = self(users_onehot, movies_onehot)\n        return output.squeeze().tolist()  # Convert tensor to list of ratings","metadata":{"execution":{"iopub.status.busy":"2024-02-23T08:57:49.298903Z","iopub.execute_input":"2024-02-23T08:57:49.299209Z","iopub.status.idle":"2024-02-23T08:57:49.307733Z","shell.execute_reply.started":"2024-02-23T08:57:49.299188Z","shell.execute_reply":"2024-02-23T08:57:49.306921Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"\nfrom sklearn.model_selection import train_test_split\n\n# Assuming 'userId' is the column representing users in your DataFrame\ndf_train, df_valid = train_test_split(df, test_size=0.1, random_state=42, stratify=df['userId'].values)\nprint(\"Size of Training Set:\", len(df_train))\nprint(\"Size of Validation Set:\", len(df_valid))\n# Extract highest rated movie for each user in the training set\nhighest_ratings_train = df_train.loc[df_train.groupby('userId')['rating'].idxmax()]\n\n# Remove these highest rated movies from the training set\ndf_train = df_train.drop(highest_ratings_train.index)\n\n# Add these highest rated movies to the validation set\ndf_valid = pd.concat([df_valid, highest_ratings_train], ignore_index=True)\n# Extract lowest rated movie for each user in the validation set\nlowest_ratings_valid = df_valid.loc[df_valid.groupby('userId')['rating'].idxmin()]\n\n# Remove these lowest rated movies from the validation set\ndf_valid = df_valid.drop(lowest_ratings_valid.index)\n\n# Add these lowest rated movies to the training set\ndf_train = pd.concat([df_train, lowest_ratings_valid], ignore_index=True)\n\nprint(\"Size of Training Set after removing highest ratings:\", len(df_train))\nprint(\"Size of Validation Set after adding highest ratings:\", len(df_valid))\n\n# Create datasets\ntrain_dataset = MovieDataset(df_train, n_users, n_movies)\nvalid_dataset = MovieDataset(df_valid, n_users, n_movies)\n\n# Create data loaders\ntrain_loader = DataLoader(dataset=train_dataset, batch_size=4, shuffle=True, num_workers=2)\nvalidation_loader = DataLoader(dataset=valid_dataset, batch_size=4, shuffle=True, num_workers=2)\n#print(\"Unique User IDs in Training Set (Sorted):\")\n#print(sorted(df_train['userId'].unique()))\n\n#print(\"\\nUnique User IDs in Validation Set (Sorted):\")\n#print(sorted(df_valid['userId'].unique()))\n","metadata":{"execution":{"iopub.status.busy":"2024-02-23T08:57:49.308890Z","iopub.execute_input":"2024-02-23T08:57:49.309596Z","iopub.status.idle":"2024-02-23T08:57:49.478437Z","shell.execute_reply.started":"2024-02-23T08:57:49.309571Z","shell.execute_reply":"2024-02-23T08:57:49.477636Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Size of Training Set: 90752\nSize of Validation Set: 10084\nSize of Training Set after removing highest ratings: 90752\nSize of Validation Set after adding highest ratings: 10084\n","output_type":"stream"}]},{"cell_type":"code","source":"# Choose the first user ID (assuming user IDs start from 1)\nfirst_user_id = 1\n\n# Filter the training set for the first user\ntraining_ratings_first_user = df_train[df_train['userId'] == first_user_id]\n\n# Filter the validation set for the first user\nvalidation_ratings_first_user = df_valid[df_valid['userId'] == first_user_id]\n\n# Print information for the training set\nprint(f\"Training Set - User {first_user_id} Ratings:\")\nprint(training_ratings_first_user[['movieId', 'rating']])\n\n# Print information for the validation set\nprint(f\"\\nValidation Set - User {first_user_id} Ratings:\")\nprint(validation_ratings_first_user[['movieId', 'rating']])\n","metadata":{"execution":{"iopub.status.busy":"2024-02-23T08:57:49.479406Z","iopub.execute_input":"2024-02-23T08:57:49.479739Z","iopub.status.idle":"2024-02-23T08:57:49.495227Z","shell.execute_reply.started":"2024-02-23T08:57:49.479716Z","shell.execute_reply":"2024-02-23T08:57:49.493880Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Training Set - User 1 Ratings:\n       movieId  rating\n1097      1552     4.0\n1525      2253     2.0\n2051      1219     2.0\n2808       954     5.0\n2861      1805     4.0\n...        ...     ...\n88061     2899     5.0\n88246     2099     4.0\n88534     2617     2.0\n89683       47     5.0\n90142     2389     2.0\n\n[209 rows x 2 columns]\n\nValidation Set - User 1 Ratings:\n       movieId  rating\n328       1777     4.0\n495        590     4.0\n743       3479     4.0\n1095      1029     5.0\n1307      2174     4.0\n1761      2596     5.0\n1868      2985     4.0\n2178      2273     4.0\n2468      1136     5.0\n2523      1240     5.0\n2577       943     4.0\n2775      3247     3.0\n2854      2944     5.0\n3170      1377     3.0\n3662       356     4.0\n5534      1517     5.0\n5833      2078     5.0\n6361      2478     4.0\n6882      3740     4.0\n8634      2502     5.0\n8681      1804     5.0\n9929      1258     3.0\n10084     2115     5.0\n","output_type":"stream"}]},{"cell_type":"code","source":"dataiter = iter(train_loader)\n\nfor dataloader_data in dataiter:\n    print(dataloader_data)\n    break","metadata":{"execution":{"iopub.status.busy":"2024-02-23T08:57:49.496329Z","iopub.execute_input":"2024-02-23T08:57:49.496643Z","iopub.status.idle":"2024-02-23T08:57:49.653579Z","shell.execute_reply.started":"2024-02-23T08:57:49.496620Z","shell.execute_reply":"2024-02-23T08:57:49.652741Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"{'users_onehot': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.]]), 'movies_onehot': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.]]), 'ratings': tensor([3.5000, 0.5000, 5.0000, 4.0000])}\n","output_type":"stream"}]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","metadata":{"execution":{"iopub.status.busy":"2024-02-23T08:57:49.655121Z","iopub.execute_input":"2024-02-23T08:57:49.655596Z","iopub.status.idle":"2024-02-23T08:57:49.659562Z","shell.execute_reply.started":"2024-02-23T08:57:49.655569Z","shell.execute_reply":"2024-02-23T08:57:49.658692Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"model = RecSysModel(\n    n_users, n_movies, emb_size=32\n).to(device)\n\n# Optimizer and scheduler\n#optimizer = torch.optim.Adam(model.parameters())\noptimizer = torch.optim.Adam(model.parameters(), lr=0.0001)  # Setting learning rate to 0.001\n\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.7)\n\n# Loss function\nloss_func = nn.MSELoss()","metadata":{"execution":{"iopub.status.busy":"2024-02-23T08:57:49.660833Z","iopub.execute_input":"2024-02-23T08:57:49.661612Z","iopub.status.idle":"2024-02-23T08:57:49.726572Z","shell.execute_reply.started":"2024-02-23T08:57:49.661583Z","shell.execute_reply":"2024-02-23T08:57:49.725889Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"print(n_users)\nprint(n_movies)\nprint(df.movieId.max() + 1)  # Adding 1 because movieId starts from 0 after one-hot encoding\nprint(len(train_dataset))\n","metadata":{"execution":{"iopub.status.busy":"2024-02-23T08:57:49.727802Z","iopub.execute_input":"2024-02-23T08:57:49.728368Z","iopub.status.idle":"2024-02-23T08:57:49.734379Z","shell.execute_reply.started":"2024-02-23T08:57:49.728345Z","shell.execute_reply":"2024-02-23T08:57:49.733319Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"610\n193610\n193610\n90752\n","output_type":"stream"}]},{"cell_type":"code","source":"with torch.no_grad():\n    model_output = model(dataloader_data['users_onehot'], \n                         dataloader_data['movies_onehot'])\n\n    print(f\"model_output: {model_output}, size: {model_output.size()}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-02-23T08:57:49.735745Z","iopub.execute_input":"2024-02-23T08:57:49.735979Z","iopub.status.idle":"2024-02-23T08:57:49.761200Z","shell.execute_reply.started":"2024-02-23T08:57:49.735958Z","shell.execute_reply":"2024-02-23T08:57:49.760125Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"model_output: tensor([[0.3654],\n        [0.3654],\n        [0.3657],\n        [0.3651]]), size: torch.Size([4, 1])\n","output_type":"stream"}]},{"cell_type":"code","source":"rating = dataloader_data[\"ratings\"]\nprint(rating)\nprint(rating.view(4, -1))\nprint(model_output)\n\nprint(rating.sum())\n\nprint(model_output.sum() - rating.sum())","metadata":{"execution":{"iopub.status.busy":"2024-02-23T08:57:49.762323Z","iopub.execute_input":"2024-02-23T08:57:49.762677Z","iopub.status.idle":"2024-02-23T08:57:49.772304Z","shell.execute_reply.started":"2024-02-23T08:57:49.762647Z","shell.execute_reply":"2024-02-23T08:57:49.771478Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"tensor([3.5000, 0.5000, 5.0000, 4.0000])\ntensor([[3.5000],\n        [0.5000],\n        [5.0000],\n        [4.0000]])\ntensor([[0.3654],\n        [0.3654],\n        [0.3657],\n        [0.3651]])\ntensor(13.)\ntensor(-11.5384)\n","output_type":"stream"}]},{"cell_type":"code","source":"\nepochs = 1\ntotal_loss = 0\nplot_steps, print_steps = 5000, 5000\nstep_cnt = 0\nall_losses_list = [] \n\nmodel.train() \nfor epoch_i in range(epochs):\n    for i, train_data in enumerate(train_loader):\n        output = model(train_data[\"users_onehot\"], \n                       train_data[\"movies_onehot\"]\n                      ) \n        \n        rating = train_data[\"ratings\"].view(4, -1).to(torch.float32)\n\n        loss = loss_func(output, rating)\n        total_loss = total_loss + loss.sum().item()\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        step_cnt = step_cnt + len(train_data[\"users_onehot\"])\n        \n\n        if(step_cnt % plot_steps == 0):\n            avg_loss = total_loss/(len(train_data[\"users_onehot\"]) * plot_steps)\n            print(f\"epoch {epoch_i} loss at step: {step_cnt} is {avg_loss}\")\n            all_losses_list.append(avg_loss)\n            total_loss = 0  # reset total_loss","metadata":{"execution":{"iopub.status.busy":"2024-02-23T08:57:49.773507Z","iopub.execute_input":"2024-02-23T08:57:49.773729Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"epoch 0 loss at step: 5000 is 0.5115638348847628\nepoch 0 loss at step: 10000 is 0.07607634874880313\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\n\nmodel_output_list = []\ntarget_rating_list = []\n\nmodel.eval()\n\nwith torch.no_grad():\n    for i, batched_data in enumerate(validation_loader): \n        model_output = model(batched_data['users_onehot'], \n                             batched_data['movies_onehot'])\n        \n        model_output_list.append(model_output.sum().item() / len(batched_data['users_onehot']))\n\n        target_rating = batched_data[\"ratings\"]\n        \n        target_rating_list.append(target_rating.sum().item() / len(batched_data['users_onehot']))\n\n# squared If True returns MSE value, if False returns RMSE value.\nrms = mean_squared_error(target_rating_list, model_output_list, squared=False)\nprint(f\"rms: {rms}\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predicted_ratings_list = []\n\nwith torch.no_grad():\n    for i, batched_data in enumerate(validation_loader): \n        \n        model_output = model(batched_data['users_onehot'], batched_data['movies_onehot'])\n        \n        for user_idx in range(len(batched_data['users_onehot'])):\n            # Get the index of the test item (movie with the highest rating)\n            test_item_index = torch.argmax(batched_data[\"ratings\"][user_idx]).item()\n\n            # Predict rating for the test item\n            predicted_rating = model_output[user_idx, test_item_index].item()\n            predicted_ratings_list.append(predicted_rating)\n\n        \n# Calculate average predicted rating\naverage_predicted_rating = np.mean(predicted_ratings_list)\nprint(f\"Average Predicted Rating of Test Item: {average_predicted_rating}\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(df.movieId.max() + 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set the model to evaluation mode\nmodel.eval()\n\n# Initialize variables to track hits\nhits_count = 0\ntotal_users = 0\n\n# Iterate over each user\nfor user_id in df['userId'].unique():\n    if user_id == 610:\n        continue \n    # Get movies rated by the user\n    rated_movies = df[df['userId'] == user_id]\n    \n    # Sample 99 unrated movie IDs from the overall dataset\n    unrated_movie_ids = df[~df['movieId'].isin(rated_movies['movieId'])]['movieId'].unique()\n    sampled_movie_ids = np.random.choice(unrated_movie_ids, size=min(99, len(unrated_movie_ids)), replace=False)\n    \n    # Append the highest rated movie for the user from the validation set\n    highest_rated_movie_id_valid = df_valid[df_valid['userId'] == user_id].nlargest(1, 'rating')['movieId'].values[0]\n    sampled_movie_ids = np.append(sampled_movie_ids, highest_rated_movie_id_valid)\n    \n    # Initialize list to store movie ratings\n    movie_ratings = []\n    \n    # Iterate over each sampled movie\n    for movie_id in sampled_movie_ids:\n        # One-hot encode user and movie\n        user_tensor = torch.tensor([user_id], dtype=torch.long)\n        movie_tensor = torch.tensor([movie_id], dtype=torch.long)\n        \n        user_onehot = torch.zeros(1, n_users)\n        user_onehot[0, user_id] = 1.0\n        \n        movie_onehot = torch.zeros(1, n_movies)\n        movie_onehot[0, movie_id] = 1.0\n        \n        # Get predictions from the model\n        model_output = model(user_onehot, movie_onehot)\n        \n        # Store the movie ID and its predicted rating\n        movie_ratings.append((movie_id, model_output.item()))  # Assuming model_output contains the predicted rating\n    \n    # Sort the movie ratings based on predicted ratings\n    movie_ratings.sort(key=lambda x: x[1], reverse=True)\n    \n    # Check if the highest rated item is among the top 10 recommendations\n    top_10_recommendations = [movie_id for movie_id, _ in movie_ratings[:10]]\n    if highest_rated_movie_id_valid in top_10_recommendations:\n        hits_count += 1\n    \n    total_users += 1\n\n# Calculate hit rate\nhit_rate = hits_count / total_users if total_users > 0 else 0\nprint(\"Hit rate:\", hit_rate)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set the model to evaluation mode\nmodel.eval()\n\n# Initialize variables to track hits\nhits_count_top20 = 0\nhits_count_bottom20 = 0\ntotal_users_top20 = 0\ntotal_users_bottom20 = 0\n\n# Get the number of ratings provided by each user\nuser_rating_counts = df['userId'].value_counts()\n\n# Sort users based on the number of ratings they have provided\nsorted_users = user_rating_counts.index.tolist()\n\n# Select the top 20 and bottom 20 frequent users\ntop20_users = sorted_users[:122]\nbottom20_users = sorted_users[-122:]\n\n# Iterate over each user\nfor user_id in df['userId'].unique():\n    # Skip user 610\n    if user_id == 610:\n        continue\n    \n    # Get movies rated by the user\n    rated_movies = df[df['userId'] == user_id]\n    \n    # Sample 100 unrated movie IDs if available\n    unrated_movie_ids = df[~df['movieId'].isin(rated_movies['movieId'])]['movieId'].unique()\n    sampled_movie_ids = np.random.choice(unrated_movie_ids, size=min(100, len(unrated_movie_ids)), replace=False)\n    \n    # Append the highest rated movie for the user\n    highest_rated_movie_id_valid = df_valid[df_valid['userId'] == user_id].nlargest(1, 'rating')['movieId'].values[0]\n    sampled_movie_ids = np.append(sampled_movie_ids, highest_rated_movie_id_valid)\n    \n    # Initialize list to store movie ratings\n    movie_ratings = []\n    \n    # Iterate over each sampled movie\n    for movie_id in sampled_movie_ids:\n        # One-hot encode user and movie\n        user_tensor = torch.tensor([user_id], dtype=torch.long)\n        movie_tensor = torch.tensor([movie_id], dtype=torch.long)\n        \n        user_onehot = torch.zeros(1, n_users)\n        user_onehot[0, user_id] = 1.0\n        \n        movie_onehot = torch.zeros(1, n_movies)\n        movie_onehot[0, movie_id] = 1.0\n        \n        # Get predictions from the model\n        model_output = model(user_onehot, movie_onehot)\n        \n        # Store the movie ID and its predicted rating\n        movie_ratings.append((movie_id, model_output.item()))  # Assuming model_output contains the predicted rating\n    \n    # Sort the movie ratings based on predicted ratings\n    movie_ratings.sort(key=lambda x: x[1], reverse=True)\n    \n    # Check if the highest rated item is among the top 10 recommendations\n    top_10_recommendations = [movie_id for movie_id, _ in movie_ratings[:10]]\n    if user_id in top20_users:\n        if highest_rated_movie_id_valid in top_10_recommendations:\n            hits_count_top20 += 1\n        total_users_top20 += 1\n    elif user_id in bottom20_users:\n        if highest_rated_movie_id_valid in top_10_recommendations:\n            hits_count_bottom20 += 1\n        total_users_bottom20 += 1\n\n# Calculate hit rate for top 20 and bottom 20 users\nhit_rate_top20 = hits_count_top20 / total_users_top20 if total_users_top20 > 0 else 0\nhit_rate_bottom20 = hits_count_bottom20 / total_users_bottom20 if total_users_bottom20 > 0 else 0\n\nprint(\"Hit rate for top 20 frequent users:\", hit_rate_top20)\nprint(\"Hit rate for bottom 20 frequent users:\", hit_rate_bottom20)\n\n\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set the model to evaluation mode\nmodel.eval()\n\n# Initialize variables to track hits\nhits_count_top20 = 0\nhits_count_bottom20 = 0\ntotal_users_top20 = 0\ntotal_users_bottom20 = 0\n\n# Get the number of ratings provided by each user\nuser_rating_counts = df['userId'].value_counts()\n\n# Sort users based on the number of ratings they have provided\nsorted_users = user_rating_counts.index.tolist()\n\n# Select the top 20 and bottom 20 frequent users\ntop20_users = sorted_users[:61]\nbottom20_users = sorted_users[-61:]\n\n# Iterate over each user\nfor user_id in df['userId'].unique():\n    # Skip user 610\n    if user_id == 610:\n        continue\n    \n    # Get movies rated by the user\n    rated_movies = df[df['userId'] == user_id]\n    \n    # Sample 100 unrated movie IDs if available\n    unrated_movie_ids = df[~df['movieId'].isin(rated_movies['movieId'])]['movieId'].unique()\n    sampled_movie_ids = np.random.choice(unrated_movie_ids, size=min(100, len(unrated_movie_ids)), replace=False)\n    \n    # Append the highest rated movie for the user\n    highest_rated_movie_id_valid = df_valid[df_valid['userId'] == user_id].nlargest(1, 'rating')['movieId'].values[0]\n    sampled_movie_ids = np.append(sampled_movie_ids, highest_rated_movie_id_valid)\n    \n    # Initialize list to store movie ratings\n    movie_ratings = []\n    \n    # Iterate over each sampled movie\n    for movie_id in sampled_movie_ids:\n        # One-hot encode user and movie\n        user_tensor = torch.tensor([user_id], dtype=torch.long)\n        movie_tensor = torch.tensor([movie_id], dtype=torch.long)\n        \n        user_onehot = torch.zeros(1, n_users)\n        user_onehot[0, user_id] = 1.0\n        \n        movie_onehot = torch.zeros(1, n_movies)\n        movie_onehot[0, movie_id] = 1.0\n        \n        # Get predictions from the model\n        model_output = model(user_onehot, movie_onehot)\n        \n        # Store the movie ID and its predicted rating\n        movie_ratings.append((movie_id, model_output.item()))  # Assuming model_output contains the predicted rating\n    \n    # Sort the movie ratings based on predicted ratings\n    movie_ratings.sort(key=lambda x: x[1], reverse=True)\n    \n    # Check if the highest rated item is among the top 10 recommendations\n    top_10_recommendations = [movie_id for movie_id, _ in movie_ratings[:10]]\n    if user_id in top20_users:\n        if highest_rated_movie_id_valid in top_10_recommendations:\n            hits_count_top20 += 1\n        total_users_top20 += 1\n    elif user_id in bottom20_users:\n        if highest_rated_movie_id_valid in top_10_recommendations:\n            hits_count_bottom20 += 1\n        total_users_bottom20 += 1\n\n# Calculate hit rate for top 20 and bottom 20 users\nhit_rate_top20 = hits_count_top20 / total_users_top20 if total_users_top20 > 0 else 0\nhit_rate_bottom20 = hits_count_bottom20 / total_users_bottom20 if total_users_bottom20 > 0 else 0\n\nprint(\"Hit rate for top 10 frequent users:\", hit_rate_top20)\nprint(\"Hit rate for bottom 10 frequent users:\", hit_rate_bottom20)\n\n\n\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set the model to evaluation mode\nmodel.eval()\n\n# Initialize variables to track hits\nhits_count_top20 = 0\nhits_count_bottom20 = 0\ntotal_users_top20 = 0\ntotal_users_bottom20 = 0\n\n# Get the number of ratings provided by each user\nuser_rating_counts = df['userId'].value_counts()\n\n# Sort users based on the number of ratings they have provided\nsorted_users = user_rating_counts.index.tolist()\n\n# Select the top 20 and bottom 20 frequent users\ntop20_users = sorted_users[:31]\nbottom20_users = sorted_users[-31:]\n\n# Iterate over each user\nfor user_id in df['userId'].unique():\n    # Skip user 610\n    if user_id == 610:\n        continue\n    \n    # Get movies rated by the user\n    rated_movies = df[df['userId'] == user_id]\n    \n    # Sample 100 unrated movie IDs if available\n    unrated_movie_ids = df[~df['movieId'].isin(rated_movies['movieId'])]['movieId'].unique()\n    sampled_movie_ids = np.random.choice(unrated_movie_ids, size=min(100, len(unrated_movie_ids)), replace=False)\n    \n    # Append the highest rated movie for the user\n    highest_rated_movie_id_valid = df_valid[df_valid['userId'] == user_id].nlargest(1, 'rating')['movieId'].values[0]\n    sampled_movie_ids = np.append(sampled_movie_ids, highest_rated_movie_id_valid)\n    \n    # Initialize list to store movie ratings\n    movie_ratings = []\n    \n    # Iterate over each sampled movie\n    for movie_id in sampled_movie_ids:\n        # One-hot encode user and movie\n        user_tensor = torch.tensor([user_id], dtype=torch.long)\n        movie_tensor = torch.tensor([movie_id], dtype=torch.long)\n        \n        user_onehot = torch.zeros(1, n_users)\n        user_onehot[0, user_id] = 1.0\n        \n        movie_onehot = torch.zeros(1, n_movies)\n        movie_onehot[0, movie_id] = 1.0\n        \n        # Get predictions from the model\n        model_output = model(user_onehot, movie_onehot)\n        \n        # Store the movie ID and its predicted rating\n        movie_ratings.append((movie_id, model_output.item()))  # Assuming model_output contains the predicted rating\n    \n    # Sort the movie ratings based on predicted ratings\n    movie_ratings.sort(key=lambda x: x[1], reverse=True)\n    \n    # Check if the highest rated item is among the top 10 recommendations\n    top_10_recommendations = [movie_id for movie_id, _ in movie_ratings[:10]]\n    if user_id in top20_users:\n        if highest_rated_movie_id_valid in top_10_recommendations:\n            hits_count_top20 += 1\n        total_users_top20 += 1\n    elif user_id in bottom20_users:\n        if highest_rated_movie_id_valid in top_10_recommendations:\n            hits_count_bottom20 += 1\n        total_users_bottom20 += 1\n\n# Calculate hit rate for top 20 and bottom 20 users\nhit_rate_top20 = hits_count_top20 / total_users_top20 if total_users_top20 > 0 else 0\nhit_rate_bottom20 = hits_count_bottom20 / total_users_bottom20 if total_users_bottom20 > 0 else 0\n\nprint(\"Hit rate for top 5 frequent users:\", hit_rate_top20)\nprint(\"Hit rate for bottom 5 frequent users:\", hit_rate_bottom20)\n\n\n\n\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set the model to evaluation mode\nmodel.eval()\n\n# Initialize variables to track hits\nhits_count_top20 = 0\nhits_count_bottom20 = 0\ntotal_users_top20 = 0\ntotal_users_bottom20 = 0\n\n# Get the number of ratings provided by each user\nuser_rating_counts = df['userId'].value_counts()\n\n# Sort users based on the number of ratings they have provided\nsorted_users = user_rating_counts.index.tolist()\n\n# Select the top 20 and bottom 20 frequent users\ntop20_users = sorted_users[:20]\nbottom20_users = sorted_users[-20:]\n\n# Iterate over each user\nfor user_id in df['userId'].unique():\n    # Skip user 610\n    if user_id == 610:\n        continue\n    \n    # Get movies rated by the user\n    rated_movies = df[df['userId'] == user_id]\n    \n    # Sample 100 unrated movie IDs if available\n    unrated_movie_ids = df[~df['movieId'].isin(rated_movies['movieId'])]['movieId'].unique()\n    sampled_movie_ids = np.random.choice(unrated_movie_ids, size=min(100, len(unrated_movie_ids)), replace=False)\n    \n    # Append the highest rated movie for the user\n    highest_rated_movie_id_valid = df_valid[df_valid['userId'] == user_id].nlargest(1, 'rating')['movieId'].values[0]\n    sampled_movie_ids = np.append(sampled_movie_ids, highest_rated_movie_id_valid)\n    \n    # Initialize list to store movie ratings\n    movie_ratings = []\n    \n    # Iterate over each sampled movie\n    for movie_id in sampled_movie_ids:\n        # One-hot encode user and movie\n        user_tensor = torch.tensor([user_id], dtype=torch.long)\n        movie_tensor = torch.tensor([movie_id], dtype=torch.long)\n        \n        user_onehot = torch.zeros(1, n_users)\n        user_onehot[0, user_id] = 1.0\n        \n        movie_onehot = torch.zeros(1, n_movies)\n        movie_onehot[0, movie_id] = 1.0\n        \n        # Get predictions from the model\n        model_output = model(user_onehot, movie_onehot)\n        \n        # Store the movie ID and its predicted rating\n        movie_ratings.append((movie_id, model_output.item()))  # Assuming model_output contains the predicted rating\n    \n    # Sort the movie ratings based on predicted ratings\n    movie_ratings.sort(key=lambda x: x[1], reverse=True)\n    \n    # Check if the highest rated item is among the top 10 recommendations\n    top_10_recommendations = [movie_id for movie_id, _ in movie_ratings[:10]]\n    if user_id in top20_users:\n        if highest_rated_movie_id_valid in top_10_recommendations:\n            hits_count_top20 += 1\n        total_users_top20 += 1\n    elif user_id in bottom20_users:\n        if highest_rated_movie_id_valid in top_10_recommendations:\n            hits_count_bottom20 += 1\n        total_users_bottom20 += 1\n\n# Calculate hit rate for top 20 and bottom 20 users\nhit_rate_top20 = hits_count_top20 / total_users_top20 if total_users_top20 > 0 else 0\nhit_rate_bottom20 = hits_count_bottom20 / total_users_bottom20 if total_users_bottom20 > 0 else 0\n\nprint(\"Hit rate for top 20 frequent users:\", hit_rate_top20)\nprint(\"Hit rate for bottom 20 frequent users:\", hit_rate_bottom20)\n\n\n\n\n\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set the model to evaluation mode\nmodel.eval()\n\n# Initialize variables to track hits\nhits_count_top20 = 0\nhits_count_bottom20 = 0\ntotal_users_top20 = 0\ntotal_users_bottom20 = 0\n\n# Get the number of ratings provided by each user\nuser_rating_counts = df['userId'].value_counts()\n\n# Sort users based on the number of ratings they have provided\nsorted_users = user_rating_counts.index.tolist()\n\n# Select the top 20 and bottom 20 frequent users\ntop20_users = sorted_users[:10]\nbottom20_users = sorted_users[-10:]\n\n# Iterate over each user\nfor user_id in df['userId'].unique():\n    # Skip user 610\n    if user_id == 610:\n        continue\n    \n    # Get movies rated by the user\n    rated_movies = df[df['userId'] == user_id]\n    \n    # Sample 100 unrated movie IDs if available\n    unrated_movie_ids = df[~df['movieId'].isin(rated_movies['movieId'])]['movieId'].unique()\n    sampled_movie_ids = np.random.choice(unrated_movie_ids, size=min(100, len(unrated_movie_ids)), replace=False)\n    \n    # Append the highest rated movie for the user\n    highest_rated_movie_id_valid = df_valid[df_valid['userId'] == user_id].nlargest(1, 'rating')['movieId'].values[0]\n    sampled_movie_ids = np.append(sampled_movie_ids, highest_rated_movie_id_valid)\n    \n    # Initialize list to store movie ratings\n    movie_ratings = []\n    \n    # Iterate over each sampled movie\n    for movie_id in sampled_movie_ids:\n        # One-hot encode user and movie\n        user_tensor = torch.tensor([user_id], dtype=torch.long)\n        movie_tensor = torch.tensor([movie_id], dtype=torch.long)\n        \n        user_onehot = torch.zeros(1, n_users)\n        user_onehot[0, user_id] = 1.0\n        \n        movie_onehot = torch.zeros(1, n_movies)\n        movie_onehot[0, movie_id] = 1.0\n        \n        # Get predictions from the model\n        model_output = model(user_onehot, movie_onehot)\n        \n        # Store the movie ID and its predicted rating\n        movie_ratings.append((movie_id, model_output.item()))  # Assuming model_output contains the predicted rating\n    \n    # Sort the movie ratings based on predicted ratings\n    movie_ratings.sort(key=lambda x: x[1], reverse=True)\n    \n    # Check if the highest rated item is among the top 10 recommendations\n    top_10_recommendations = [movie_id for movie_id, _ in movie_ratings[:10]]\n    if user_id in top20_users:\n        if highest_rated_movie_id_valid in top_10_recommendations:\n            hits_count_top20 += 1\n        total_users_top20 += 1\n    elif user_id in bottom20_users:\n        if highest_rated_movie_id_valid in top_10_recommendations:\n            hits_count_bottom20 += 1\n        total_users_bottom20 += 1\n\n# Calculate hit rate for top 20 and bottom 20 users\nhit_rate_top20 = hits_count_top20 / total_users_top20 if total_users_top20 > 0 else 0\nhit_rate_bottom20 = hits_count_bottom20 / total_users_bottom20 if total_users_bottom20 > 0 else 0\n\nprint(\"Hit rate for top 10 frequent users:\", hit_rate_top20)\nprint(\"Hit rate for bottom 10 frequent users:\", hit_rate_bottom20)\n\n\n\n\n\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set the model to evaluation mode\nmodel.eval()\n\n# Initialize variables to track hits\nhits_count_top20 = 0\nhits_count_bottom20 = 0\ntotal_users_top20 = 0\ntotal_users_bottom20 = 0\n\n# Get the number of ratings provided by each user\nuser_rating_counts = df['userId'].value_counts()\n\n# Sort users based on the number of ratings they have provided\nsorted_users = user_rating_counts.index.tolist()\n\n# Select the top 20 and bottom 20 frequent users\ntop20_users = sorted_users[:5]\nbottom20_users = sorted_users[-5:]\n\n# Iterate over each user\nfor user_id in df['userId'].unique():\n    # Skip user 610\n    if user_id == 610:\n        continue\n    \n    # Get movies rated by the user\n    rated_movies = df[df['userId'] == user_id]\n    \n    # Sample 100 unrated movie IDs if available\n    unrated_movie_ids = df[~df['movieId'].isin(rated_movies['movieId'])]['movieId'].unique()\n    sampled_movie_ids = np.random.choice(unrated_movie_ids, size=min(100, len(unrated_movie_ids)), replace=False)\n    \n    # Append the highest rated movie for the user\n    highest_rated_movie_id_valid = df_valid[df_valid['userId'] == user_id].nlargest(1, 'rating')['movieId'].values[0]\n    sampled_movie_ids = np.append(sampled_movie_ids, highest_rated_movie_id_valid)\n    \n    # Initialize list to store movie ratings\n    movie_ratings = []\n    \n    # Iterate over each sampled movie\n    for movie_id in sampled_movie_ids:\n        # One-hot encode user and movie\n        user_tensor = torch.tensor([user_id], dtype=torch.long)\n        movie_tensor = torch.tensor([movie_id], dtype=torch.long)\n        \n        user_onehot = torch.zeros(1, n_users)\n        user_onehot[0, user_id] = 1.0\n        \n        movie_onehot = torch.zeros(1, n_movies)\n        movie_onehot[0, movie_id] = 1.0\n        \n        # Get predictions from the model\n        model_output = model(user_onehot, movie_onehot)\n        \n        # Store the movie ID and its predicted rating\n        movie_ratings.append((movie_id, model_output.item()))  # Assuming model_output contains the predicted rating\n    \n    # Sort the movie ratings based on predicted ratings\n    movie_ratings.sort(key=lambda x: x[1], reverse=True)\n    \n    # Check if the highest rated item is among the top 10 recommendations\n    top_10_recommendations = [movie_id for movie_id, _ in movie_ratings[:10]]\n    if user_id in top20_users:\n        if highest_rated_movie_id_valid in top_10_recommendations:\n            hits_count_top20 += 1\n        total_users_top20 += 1\n    elif user_id in bottom20_users:\n        if highest_rated_movie_id_valid in top_10_recommendations:\n            hits_count_bottom20 += 1\n        total_users_bottom20 += 1\n\n# Calculate hit rate for top 20 and bottom 20 users\nhit_rate_top20 = hits_count_top20 / total_users_top20 if total_users_top20 > 0 else 0\nhit_rate_bottom20 = hits_count_bottom20 / total_users_bottom20 if total_users_bottom20 > 0 else 0\n\nprint(\"Hit rate for top 5 frequent users:\", hit_rate_top20)\nprint(\"Hit rate for bottom 5 frequent users:\", hit_rate_bottom20)\n\n\n\n\n\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set the model to evaluation mode\nmodel.eval()\n\n# Initialize variables to track hits\nhits_count_top20 = 0\nhits_count_bottom20 = 0\ntotal_users_top20 = 0\ntotal_users_bottom20 = 0\n\n# Get the number of ratings provided by each user\nuser_rating_counts = df['userId'].value_counts()\n\n# Sort users based on the number of ratings they have provided\nsorted_users = user_rating_counts.index.tolist()\n\n# Select the top 20 and bottom 20 frequent users\ntop20_users = sorted_users[:31]\nbottom20_users = sorted_users[-31:]\n\n# Iterate over each user\nfor user_id in df['userId'].unique():\n    # Skip user 610\n    if user_id == 610:\n        continue\n    \n    # Get movies rated by the user\n    rated_movies = df[df['userId'] == user_id]\n    \n    # Sample 100 unrated movie IDs if available\n    unrated_movie_ids = df[~df['movieId'].isin(rated_movies['movieId'])]['movieId'].unique()\n    sampled_movie_ids = np.random.choice(unrated_movie_ids, size=min(100, len(unrated_movie_ids)), replace=False)\n    \n    # Append the highest rated movie for the user\n    highest_rated_movie_id_valid = df_valid[df_valid['userId'] == user_id].nlargest(1, 'rating')['movieId'].values[0]\n    sampled_movie_ids = np.append(sampled_movie_ids, highest_rated_movie_id_valid)\n    \n    # Initialize list to store movie ratings\n    movie_ratings = []\n    \n    # Iterate over each sampled movie\n    for movie_id in sampled_movie_ids:\n        # One-hot encode user and movie\n        user_tensor = torch.tensor([user_id], dtype=torch.long)\n        movie_tensor = torch.tensor([movie_id], dtype=torch.long)\n        \n        user_onehot = torch.zeros(1, n_users)\n        user_onehot[0, user_id] = 1.0\n        \n        movie_onehot = torch.zeros(1, n_movies)\n        movie_onehot[0, movie_id] = 1.0\n        \n        # Get predictions from the model\n        model_output = model(user_onehot, movie_onehot)\n        \n        # Store the movie ID and its predicted rating\n        movie_ratings.append((movie_id, model_output.item()))  # Assuming model_output contains the predicted rating\n    \n    # Sort the movie ratings based on predicted ratings\n    movie_ratings.sort(key=lambda x: x[1], reverse=True)\n    \n    # Check if the highest rated item is among the top 10 recommendations\n    top_10_recommendations = [movie_id for movie_id, _ in movie_ratings[:10]]\n    if user_id in top20_users:\n        if highest_rated_movie_id_valid in top_10_recommendations:\n            hits_count_top20 += 1\n        total_users_top20 += 1\n    elif user_id in bottom20_users:\n        if highest_rated_movie_id_valid in top_10_recommendations:\n            hits_count_bottom20 += 1\n        total_users_bottom20 += 1\n\n# Calculate hit rate for top 20 and bottom 20 users\nhit_rate_top20 = hits_count_top20 / total_users_top20 if total_users_top20 > 0 else 0\nhit_rate_bottom20 = hits_count_bottom20 / total_users_bottom20 if total_users_bottom20 > 0 else 0\n\nprint(\"Hit rate for top 10 frequent users:\", hit_rate_top20)\nprint(\"Hit rate for bottom 10 frequent users:\", hit_rate_bottom20)\n\n\n\n\n\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Print the indices of the top 10 users and their total rating count\nprint(\"Indices and total rating count of the top 10 users:\")\nfor index, user_id in enumerate(sorted_users[:10]):\n    print(\"Index:\", index, \"User ID:\", user_id, \"Total Rating Count:\", user_rating_counts[user_id])\n\n# Print the indices of the bottom 10 users and their total rating count\nprint(\"Indices and total rating count of the bottom 10 users:\")\nfor index, user_id in enumerate(sorted_users[-10:], start=len(sorted_users) - 10):\n    print(\"Index:\", index, \"User ID:\", user_id, \"Total Rating Count:\", user_rating_counts[user_id])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Print the indices of the top 10 users\nprint(\"Indices of the top 10 users:\")\nfor index, user_id in enumerate(sorted_users[:10]):\n    print(index, user_id)\n\n# Print the indices of the bottom 10 users\nprint(\"Indices of the bottom 10 users:\")\nfor index, user_id in enumerate(sorted_users[-10:], start=len(sorted_users) - 10):\n    print(index, user_id)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set the model to evaluation mode\nmodel.eval()\n\n# Initialize variables to track hits\nhits_count_top20 = 0\nhits_count_bottom20 = 0\ntotal_users_top20 = 0\ntotal_users_bottom20 = 0\n\n# Get the number of ratings provided by each user\nuser_rating_counts = df['userId'].value_counts()\n\n# Sort users based on the number of ratings they have provided\nsorted_users = user_rating_counts.index.tolist()\n\n# Select the top 20 and bottom 20 frequent users\ntop20_users = sorted_users[:122]\nbottom20_users = sorted_users[-122:]\n\n# Iterate over each user\nfor user_id in df['userId'].unique():\n    # Skip user 610\n    if user_id == 610:\n        continue\n    \n    # Get movies rated by the user\n    rated_movies = df[df['userId'] == user_id]\n    \n    # Sample 100 unrated movie IDs if available\n    unrated_movie_ids = df[~df['movieId'].isin(rated_movies['movieId'])]['movieId'].unique()\n    sampled_movie_ids = np.random.choice(unrated_movie_ids, size=min(100, len(unrated_movie_ids)), replace=False)\n    \n    # Append the highest rated movie for the user\n    highest_rated_movie_id = rated_movies.nlargest(1, 'rating')['movieId'].values[0]\n    sampled_movie_ids = np.append(sampled_movie_ids, highest_rated_movie_id)\n    \n    # Initialize list to store movie ratings\n    movie_ratings = []\n    \n    # Iterate over each sampled movie\n    for movie_id in sampled_movie_ids:\n        # One-hot encode user and movie\n        user_tensor = torch.tensor([user_id], dtype=torch.long)\n        movie_tensor = torch.tensor([movie_id], dtype=torch.long)\n        \n        user_onehot = torch.zeros(1, n_users)\n        user_onehot[0, user_id] = 1.0\n        \n        movie_onehot = torch.zeros(1, n_movies)\n        movie_onehot[0, movie_id] = 1.0\n        \n        # Get predictions from the model\n        model_output = model(user_onehot, movie_onehot)\n        \n        # Store the movie ID and its predicted rating\n        movie_ratings.append((movie_id, model_output.item()))  # Assuming model_output contains the predicted rating\n    \n    # Sort the movie ratings based on predicted ratings\n    movie_ratings.sort(key=lambda x: x[1], reverse=True)\n    \n    # Check if the highest rated item is among the top 10 recommendations\n    top_10_recommendations = [movie_id for movie_id, _ in movie_ratings[:10]]\n    if user_id in top20_users:\n        if highest_rated_movie_id in top_10_recommendations:\n            hits_count_top20 += 1\n        total_users_top20 += 1\n    elif user_id in bottom20_users:\n        if highest_rated_movie_id in top_10_recommendations:\n            hits_count_bottom20 += 1\n        total_users_bottom20 += 1\n\n# Calculate hit rate for top 20 and bottom 20 users\nhit_rate_top20 = hits_count_top20 / total_users_top20 if total_users_top20 > 0 else 0\nhit_rate_bottom20 = hits_count_bottom20 / total_users_bottom20 if total_users_bottom20 > 0 else 0\n\nprint(\"Hit rate for top 5 frequent users:\", hit_rate_top20)\nprint(\"Hit rate for bottom 5 frequent users:\", hit_rate_bottom20)\n\n\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set the model to evaluation mode\nmodel.eval()\n\n# Initialize variables to track hits\nhits_count_top20 = 0\nhits_count_bottom20 = 0\ntotal_users_top20 = 0\ntotal_users_bottom20 = 0\n\n# Get the number of ratings provided by each user\nuser_rating_counts = df['userId'].value_counts()\n\n# Sort users based on the number of ratings they have provided\nsorted_users = user_rating_counts.index.tolist()\n\n# Select the top 20 and bottom 20 frequent users\ntop20_users = sorted_users[:61]\nbottom20_users = sorted_users[-61:]\n\n# Iterate over each user\nfor user_id in df['userId'].unique():\n    # Skip user 610\n    if user_id == 610:\n        continue\n    \n    # Get movies rated by the user\n    rated_movies = df[df['userId'] == user_id]\n    \n    # Sample 100 unrated movie IDs if available\n    unrated_movie_ids = df[~df['movieId'].isin(rated_movies['movieId'])]['movieId'].unique()\n    sampled_movie_ids = np.random.choice(unrated_movie_ids, size=min(100, len(unrated_movie_ids)), replace=False)\n    \n    # Append the highest rated movie for the user\n    highest_rated_movie_id = rated_movies.nlargest(1, 'rating')['movieId'].values[0]\n    sampled_movie_ids = np.append(sampled_movie_ids, highest_rated_movie_id)\n    \n    # Initialize list to store movie ratings\n    movie_ratings = []\n    \n    # Iterate over each sampled movie\n    for movie_id in sampled_movie_ids:\n        # One-hot encode user and movie\n        user_tensor = torch.tensor([user_id], dtype=torch.long)\n        movie_tensor = torch.tensor([movie_id], dtype=torch.long)\n        \n        user_onehot = torch.zeros(1, n_users)\n        user_onehot[0, user_id] = 1.0\n        \n        movie_onehot = torch.zeros(1, n_movies)\n        movie_onehot[0, movie_id] = 1.0\n        \n        # Get predictions from the model\n        model_output = model(user_onehot, movie_onehot)\n        \n        # Store the movie ID and its predicted rating\n        movie_ratings.append((movie_id, model_output.item()))  # Assuming model_output contains the predicted rating\n    \n    # Sort the movie ratings based on predicted ratings\n    movie_ratings.sort(key=lambda x: x[1], reverse=True)\n    \n    # Check if the highest rated item is among the top 10 recommendations\n    top_10_recommendations = [movie_id for movie_id, _ in movie_ratings[:10]]\n    if user_id in top20_users:\n        if highest_rated_movie_id in top_10_recommendations:\n            hits_count_top20 += 1\n        total_users_top20 += 1\n    elif user_id in bottom20_users:\n        if highest_rated_movie_id in top_10_recommendations:\n            hits_count_bottom20 += 1\n        total_users_bottom20 += 1\n\n# Calculate hit rate for top 20 and bottom 20 users\nhit_rate_top20 = hits_count_top20 / total_users_top20 if total_users_top20 > 0 else 0\nhit_rate_bottom20 = hits_count_bottom20 / total_users_bottom20 if total_users_bottom20 > 0 else 0\n\nprint(\"Hit rate for top 10 frequent users:\", hit_rate_top20)\nprint(\"Hit rate for bottom 10 frequent users:\", hit_rate_bottom20)\n\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set the model to evaluation mode\nmodel.eval()\n\n# Initialize variables to track hits\nhits_count_top20 = 0\nhits_count_bottom20 = 0\ntotal_users_top20 = 0\ntotal_users_bottom20 = 0\n\n# Get the number of ratings provided by each user\nuser_rating_counts = df['userId'].value_counts()\n\n# Sort users based on the number of ratings they have provided\nsorted_users = user_rating_counts.index.tolist()\n\n# Select the top 20 and bottom 20 frequent users\ntop20_users = sorted_users[:31]\nbottom20_users = sorted_users[-31:]\n\n# Iterate over each user\nfor user_id in df['userId'].unique():\n    # Skip user 610\n    if user_id == 610:\n        continue\n    \n    # Get movies rated by the user\n    rated_movies = df[df['userId'] == user_id]\n    \n    # Sample 100 unrated movie IDs if available\n    unrated_movie_ids = df[~df['movieId'].isin(rated_movies['movieId'])]['movieId'].unique()\n    sampled_movie_ids = np.random.choice(unrated_movie_ids, size=min(100, len(unrated_movie_ids)), replace=False)\n    \n    # Append the highest rated movie for the user\n    highest_rated_movie_id = rated_movies.nlargest(1, 'rating')['movieId'].values[0]\n    sampled_movie_ids = np.append(sampled_movie_ids, highest_rated_movie_id)\n    \n    # Initialize list to store movie ratings\n    movie_ratings = []\n    \n    # Iterate over each sampled movie\n    for movie_id in sampled_movie_ids:\n        # One-hot encode user and movie\n        user_tensor = torch.tensor([user_id], dtype=torch.long)\n        movie_tensor = torch.tensor([movie_id], dtype=torch.long)\n        \n        user_onehot = torch.zeros(1, n_users)\n        user_onehot[0, user_id] = 1.0\n        \n        movie_onehot = torch.zeros(1, n_movies)\n        movie_onehot[0, movie_id] = 1.0\n        \n        # Get predictions from the model\n        model_output = model(user_onehot, movie_onehot)\n        \n        # Store the movie ID and its predicted rating\n        movie_ratings.append((movie_id, model_output.item()))  # Assuming model_output contains the predicted rating\n    \n    # Sort the movie ratings based on predicted ratings\n    movie_ratings.sort(key=lambda x: x[1], reverse=True)\n    \n    # Check if the highest rated item is among the top 10 recommendations\n    top_10_recommendations = [movie_id for movie_id, _ in movie_ratings[:10]]\n    if user_id in top20_users:\n        if highest_rated_movie_id in top_10_recommendations:\n            hits_count_top20 += 1\n        total_users_top20 += 1\n    elif user_id in bottom20_users:\n        if highest_rated_movie_id in top_10_recommendations:\n            hits_count_bottom20 += 1\n        total_users_bottom20 += 1\n\n# Calculate hit rate for top 20 and bottom 20 users\nhit_rate_top20 = hits_count_top20 / total_users_top20 if total_users_top20 > 0 else 0\nhit_rate_bottom20 = hits_count_bottom20 / total_users_bottom20 if total_users_bottom20 > 0 else 0\n\nprint(\"Hit rate for top 5 frequent users:\", hit_rate_top20)\nprint(\"Hit rate for bottom 5 frequent users:\", hit_rate_bottom20)\n\n\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set the model to evaluation mode\nmodel.eval()\n\n# Initialize variables to track hits\nhits_count_top20 = 0\nhits_count_bottom20 = 0\ntotal_users_top20 = 0\ntotal_users_bottom20 = 0\n\n# Get the number of ratings provided by each user\nuser_rating_counts = df['userId'].value_counts()\n\n# Sort users based on the number of ratings they have provided\nsorted_users = user_rating_counts.index.tolist()\n\n# Select the top 20 and bottom 20 frequent users\ntop20_users = sorted_users[:10]\nbottom20_users = sorted_users[-10:]\n\n# Iterate over each user\nfor user_id in df['userId'].unique():\n    # Skip user 610\n    if user_id == 610:\n        continue\n    \n    # Get movies rated by the user\n    rated_movies = df[df['userId'] == user_id]\n    \n    # Sample 100 unrated movie IDs if available\n    unrated_movie_ids = df[~df['movieId'].isin(rated_movies['movieId'])]['movieId'].unique()\n    sampled_movie_ids = np.random.choice(unrated_movie_ids, size=min(100, len(unrated_movie_ids)), replace=False)\n    \n    # Append the highest rated movie for the user\n    highest_rated_movie_id = rated_movies.nlargest(1, 'rating')['movieId'].values[0]\n    sampled_movie_ids = np.append(sampled_movie_ids, highest_rated_movie_id)\n    \n    # Initialize list to store movie ratings\n    movie_ratings = []\n    \n    # Iterate over each sampled movie\n    for movie_id in sampled_movie_ids:\n        # One-hot encode user and movie\n        user_tensor = torch.tensor([user_id], dtype=torch.long)\n        movie_tensor = torch.tensor([movie_id], dtype=torch.long)\n        \n        user_onehot = torch.zeros(1, n_users)\n        user_onehot[0, user_id] = 1.0\n        \n        movie_onehot = torch.zeros(1, n_movies)\n        movie_onehot[0, movie_id] = 1.0\n        \n        # Get predictions from the model\n        model_output = model(user_onehot, movie_onehot)\n        \n        # Store the movie ID and its predicted rating\n        movie_ratings.append((movie_id, model_output.item()))  # Assuming model_output contains the predicted rating\n    \n    # Sort the movie ratings based on predicted ratings\n    movie_ratings.sort(key=lambda x: x[1], reverse=True)\n    \n    # Check if the highest rated item is among the top 10 recommendations\n    top_10_recommendations = [movie_id for movie_id, _ in movie_ratings[:10]]\n    if user_id in top20_users:\n        if highest_rated_movie_id in top_10_recommendations:\n            hits_count_top20 += 1\n        total_users_top20 += 1\n    elif user_id in bottom20_users:\n        if highest_rated_movie_id in top_10_recommendations:\n            hits_count_bottom20 += 1\n        total_users_bottom20 += 1\n\n# Calculate hit rate for top 20 and bottom 20 users\nhit_rate_top20 = hits_count_top20 / total_users_top20 if total_users_top20 > 0 else 0\nhit_rate_bottom20 = hits_count_bottom20 / total_users_bottom20 if total_users_bottom20 > 0 else 0\n\nprint(\"Hit rate for top 10 frequent users:\", hit_rate_top20)\nprint(\"Hit rate for bottom 10 frequent users:\", hit_rate_bottom20)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set the model to evaluation mode\nmodel.eval()\n\n# Initialize variables to track hits\nhits_count_top20 = 0\nhits_count_bottom20 = 0\ntotal_users_top20 = 0\ntotal_users_bottom20 = 0\n\n# Get the number of ratings provided by each user\nuser_rating_counts = df['userId'].value_counts()\n\n# Sort users based on the number of ratings they have provided\nsorted_users = user_rating_counts.index.tolist()\n\n# Select the top 20 and bottom 20 frequent users\ntop20_users = sorted_users[:10]\nbottom20_users = sorted_users[-10:]\n\n# Iterate over each user\nfor user_id in df['userId'].unique():\n    # Skip user 610\n    if user_id == 610:\n        continue\n    \n    # Get movies rated by the user\n    rated_movies = df[df['userId'] == user_id]\n    \n    # Sample 100 unrated movie IDs if available\n    unrated_movie_ids = df[~df['movieId'].isin(rated_movies['movieId'])]['movieId'].unique()\n    sampled_movie_ids = np.random.choice(unrated_movie_ids, size=min(100, len(unrated_movie_ids)), replace=False)\n    \n    # Append the highest rated movie for the user\n    highest_rated_movie_id_valid = df_valid[df_valid['userId'] == user_id].nlargest(1, 'rating')['movieId'].values[0]\n    sampled_movie_ids = np.append(sampled_movie_ids, highest_rated_movie_id_valid)\n    \n    # Initialize list to store movie ratings\n    movie_ratings = []\n    \n    # Iterate over each sampled movie\n    for movie_id in sampled_movie_ids:\n        # One-hot encode user and movie\n        user_tensor = torch.tensor([user_id], dtype=torch.long)\n        movie_tensor = torch.tensor([movie_id], dtype=torch.long)\n        \n        user_onehot = torch.zeros(1, n_users)\n        user_onehot[0, user_id] = 1.0\n        \n        movie_onehot = torch.zeros(1, n_movies)\n        movie_onehot[0, movie_id] = 1.0\n        \n        # Get predictions from the model\n        model_output = model(user_onehot, movie_onehot)\n        \n        # Store the movie ID and its predicted rating\n        movie_ratings.append((movie_id, model_output.item()))  # Assuming model_output contains the predicted rating\n    \n    # Sort the movie ratings based on predicted ratings\n    movie_ratings.sort(key=lambda x: x[1], reverse=True)\n    \n    # Check if the highest rated item is among the top 10 recommendations\n    top_10_recommendations = [movie_id for movie_id, _ in movie_ratings[:10]]\n    if user_id in top20_users:\n        if highest_rated_movie_id_valid in top_10_recommendations:\n            hits_count_top20 += 1\n        total_users_top20 += 1\n    elif user_id in bottom20_users:\n        if highest_rated_movie_id_valid in top_10_recommendations:\n            hits_count_bottom20 += 1\n        total_users_bottom20 += 1\n\n# Calculate hit rate for top 20 and bottom 20 users\nhit_rate_top20 = hits_count_top20 / total_users_top20 if total_users_top20 > 0 else 0\nhit_rate_bottom20 = hits_count_bottom20 / total_users_bottom20 if total_users_bottom20 > 0 else 0\n\nprint(\"Hit rate for top 10 frequent users:\", hit_rate_top20)\nprint(\"Hit rate for bottom 10 frequent users:\", hit_rate_bottom20)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set the model to evaluation mode\nmodel.eval()\n\n# Initialize variables to track hits\nhits_count_top20 = 0\nhits_count_bottom20 = 0\ntotal_users_top20 = 0\ntotal_users_bottom20 = 0\n\n# Get the number of ratings provided by each user\nuser_rating_counts = df['userId'].value_counts()\n\n# Sort users based on the number of ratings they have provided\nsorted_users = user_rating_counts.index.tolist()\n\n# Select the top 20 and bottom 20 frequent users\ntop20_users = sorted_users[:5]\nbottom20_users = sorted_users[-5:]\n\n# Iterate over each user\nfor user_id in df['userId'].unique():\n    # Skip user 610\n    if user_id == 610:\n        continue\n    \n    # Get movies rated by the user\n    rated_movies = df[df['userId'] == user_id]\n    \n    # Sample 100 unrated movie IDs if available\n    unrated_movie_ids = df[~df['movieId'].isin(rated_movies['movieId'])]['movieId'].unique()\n    sampled_movie_ids = np.random.choice(unrated_movie_ids, size=min(100, len(unrated_movie_ids)), replace=False)\n    \n    # Append the highest rated movie for the user\n    highest_rated_movie_id_valid = df_valid[df_valid['userId'] == user_id].nlargest(1, 'rating')['movieId'].values[0]\n    sampled_movie_ids = np.append(sampled_movie_ids, highest_rated_movie_id_valid)\n    \n    # Initialize list to store movie ratings\n    movie_ratings = []\n    \n    # Iterate over each sampled movie\n    for movie_id in sampled_movie_ids:\n        # One-hot encode user and movie\n        user_tensor = torch.tensor([user_id], dtype=torch.long)\n        movie_tensor = torch.tensor([movie_id], dtype=torch.long)\n        \n        user_onehot = torch.zeros(1, n_users)\n        user_onehot[0, user_id] = 1.0\n        \n        movie_onehot = torch.zeros(1, n_movies)\n        movie_onehot[0, movie_id] = 1.0\n        \n        # Get predictions from the model\n        model_output = model(user_onehot, movie_onehot)\n        \n        # Store the movie ID and its predicted rating\n        movie_ratings.append((movie_id, model_output.item()))  # Assuming model_output contains the predicted rating\n    \n    # Sort the movie ratings based on predicted ratings\n    movie_ratings.sort(key=lambda x: x[1], reverse=True)\n    \n    # Check if the highest rated item is among the top 10 recommendations\n    top_10_recommendations = [movie_id for movie_id, _ in movie_ratings[:10]]\n    if user_id in top20_users:\n        if highest_rated_movie_id_valid in top_10_recommendations:\n            hits_count_top20 += 1\n        total_users_top20 += 1\n    elif user_id in bottom20_users:\n        if highest_rated_movie_id_valid in top_10_recommendations:\n            hits_count_bottom20 += 1\n        total_users_bottom20 += 1\n\n# Calculate hit rate for top 20 and bottom 20 users\nhit_rate_top20 = hits_count_top20 / total_users_top20 if total_users_top20 > 0 else 0\nhit_rate_bottom20 = hits_count_bottom20 / total_users_bottom20 if total_users_bottom20 > 0 else 0\n\nprint(\"Hit rate for top 5 frequent users:\", hit_rate_top20)\nprint(\"Hit rate for bottom 5 frequent users:\", hit_rate_bottom20)\n\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Iterate over each user\nfor user_id in df['userId'].unique():\n    # Skip user 610\n    if user_id == 610:\n        continue\n    \n    # Get movies rated by the user\n    rated_movies = df[df['userId'] == user_id]\n    \n    # Sample 100 unrated movie IDs if available\n    unrated_movie_ids = df[~df['movieId'].isin(rated_movies['movieId'])]['movieId'].unique()\n    sampled_movie_ids = np.random.choice(unrated_movie_ids, size=min(100, len(unrated_movie_ids)), replace=False)\n    \n    # Append the highest rated movie for the user\n    highest_rated_movie_id_valid = df_valid[df_valid['userId'] == user_id].nlargest(1, 'rating')['movieId'].values[0]\n    sampled_movie_ids = np.append(sampled_movie_ids, highest_rated_movie_id_valid)\n    \n    # Initialize list to store movie ratings\n    movie_ratings = []\n    \n    # Iterate over each sampled movie\n    for movie_id in sampled_movie_ids:\n        # One-hot encode user and movie\n        user_tensor = torch.tensor([user_id], dtype=torch.long)\n        movie_tensor = torch.tensor([movie_id], dtype=torch.long)\n        \n        user_onehot = torch.zeros(1, n_users)\n        user_onehot[0, user_id] = 1.0\n        \n        movie_onehot = torch.zeros(1, n_movies)\n        movie_onehot[0, movie_id] = 1.0\n        \n        # Get predictions from the model\n        model_output = model(user_onehot, movie_onehot)\n        \n        # Store the movie ID and its predicted rating\n        movie_ratings.append((movie_id, model_output.item()))  # Assuming model_output contains the predicted rating\n    \n    # Sort the movie ratings based on predicted ratings\n    movie_ratings.sort(key=lambda x: x[1], reverse=True)\n    \n    # Check if the highest rated item is among the top 10 recommendations\n    top_10_recommendations = [movie_id for movie_id, _ in movie_ratings[:10]]\n    if user_id in top20_users:\n        if highest_rated_movie_id_valid in top_10_recommendations:\n            hits_count_top20 += 1\n            # Print highest_rated_movie_id_valid and top_10_recommendations for each user\n        print(f\"User top {user_id}:\")\n        print(\"Highest Rated Movie ID (Valid):\", highest_rated_movie_id_valid)\n        print(\"Top 10 Recommendations:\", top_10_recommendations)\n        print()\n        total_users_top20 += 1\n    elif user_id in bottom20_users:\n        if highest_rated_movie_id_valid in top_10_recommendations:\n            hits_count_bottom20 += 1\n            # Print highest_rated_movie_id_valid and top_10_recommendations for each user\n        print(f\"User bottom {user_id}:\")\n        print(\"Highest Rated Movie ID (Valid):\", highest_rated_movie_id_valid)\n        print(\"Top 10 Recommendations:\", top_10_recommendations)\n        print()\n        total_users_bottom20 += 1\n    \n    \n\n# Calculate hit rate for top 20 and bottom 20 users\nhit_rate_top20 = hits_count_top20 / total_users_top20 if total_users_top20 > 0 else 0\nhit_rate_bottom20 = hits_count_bottom20 / total_users_bottom20 if total_users_bottom20 > 0 else 0\n\nprint(\"Hit rate for top 5 frequent users:\", hit_rate_top20)\nprint(\"Hit rate for bottom 5 frequent users:\", hit_rate_bottom20)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Iterate over each user\nfor user_id in df['userId'].unique():\n    # Skip user 610\n    if user_id == 610:\n        continue\n    \n    # Get movies rated by the user\n    rated_movies = df[df['userId'] == user_id]\n    \n    # Sample 100 unrated movie IDs if available\n    unrated_movie_ids = df[~df['movieId'].isin(rated_movies['movieId'])]['movieId'].unique()\n    sampled_movie_ids = np.random.choice(unrated_movie_ids, size=min(100, len(unrated_movie_ids)), replace=False)\n    \n    # Append the highest rated movie for the user\n    highest_rated_movie_id_valid = df_valid[df_valid['userId'] == user_id].nlargest(1, 'rating')['movieId'].values[0]\n    sampled_movie_ids = np.append(sampled_movie_ids, highest_rated_movie_id_valid)\n    \n    # Initialize list to store movie ratings\n    movie_ratings = []\n    \n    # Iterate over each sampled movie\n    for movie_id in sampled_movie_ids:\n        # One-hot encode user and movie\n        user_tensor = torch.tensor([user_id], dtype=torch.long)\n        movie_tensor = torch.tensor([movie_id], dtype=torch.long)\n        \n        user_onehot = torch.zeros(1, n_users)\n        user_onehot[0, user_id] = 1.0\n        \n        movie_onehot = torch.zeros(1, n_movies)\n        movie_onehot[0, movie_id] = 1.0\n        \n        # Get predictions from the model\n        model_output = model(user_onehot, movie_onehot)\n        \n        # Store the movie ID and its predicted rating\n        movie_ratings.append((movie_id, model_output.item()))  # Assuming model_output contains the predicted rating\n    \n    # Sort the movie ratings based on predicted ratings\n    movie_ratings.sort(key=lambda x: x[1], reverse=True)\n    \n    # Check if the highest rated item is among the top 10 recommendations\n    top_10_recommendations = [movie_id for movie_id, _ in movie_ratings[:10]]\n    if user_id in top20_users:\n        if highest_rated_movie_id_valid in top_10_recommendations:\n            hits_count_top20 += 1\n        total_users_top20 += 1\n    elif user_id in bottom20_users:\n        if highest_rated_movie_id_valid in top_10_recommendations:\n            hits_count_bottom20 += 1\n        total_users_bottom20 += 1\n    \n    # Print highest_rated_movie_id_valid and top_10_recommendations for each user\n    print(f\"User {user_id}:\")\n    print(\"Highest Rated Movie ID (Valid):\", highest_rated_movie_id_valid)\n    print(\"Top 10 Recommendations:\", top_10_recommendations)\n    print()\n\n# Calculate hit rate for top 20 and bottom 20 users\nhit_rate_top20 = hits_count_top20 / total_users_top20 if total_users_top20 > 0 else 0\nhit_rate_bottom20 = hits_count_bottom20 / total_users_bottom20 if total_users_bottom20 > 0 else 0\n\nprint(\"Hit rate for top 5 frequent users:\", hit_rate_top20)\nprint(\"Hit rate for bottom 5 frequent users:\", hit_rate_bottom20)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initialize dictionaries to store top 10 and test movie indices for each user in top 5 and bottom 5\ntop10_movie_indices_top5 = {}\ntest_movie_indices_top5 = {}\ntop10_movie_indices_bottom5 = {}\ntest_movie_indices_bottom5 = {}\n\n# Iterate over each user\nfor user_id in df['userId'].unique():\n    # Skip user 610\n    if user_id == 610:\n        continue\n    \n    # Get movies rated by the user\n    rated_movies = df[df['userId'] == user_id]\n    \n    # Sample 100 unrated movie IDs if available\n    unrated_movie_ids = df[~df['movieId'].isin(rated_movies['movieId'])]['movieId'].unique()\n    sampled_movie_ids = np.random.choice(unrated_movie_ids, size=min(100, len(unrated_movie_ids)), replace=False)\n    \n    # Append the highest rated movie for the user\n    highest_rated_movie_id_valid = df_valid[df_valid['userId'] == user_id].nlargest(1, 'rating')['movieId'].values[0]\n    sampled_movie_ids = np.append(sampled_movie_ids, highest_rated_movie_id_valid)\n    \n    # Store top 10 and test movie indices for each user in top 5 and bottom 5\n    if user_id in top20_users:\n        top10_movie_indices_top5[user_id] = sampled_movie_ids[:10]\n        test_movie_indices_top5[user_id] = highest_rated_movie_id_valid\n    elif user_id in bottom20_users:\n        top10_movie_indices_bottom5[user_id] = sampled_movie_ids[:10]\n        test_movie_indices_bottom5[user_id] = highest_rated_movie_id_valid\n\n# Print top 10 and test movie indices for each user separately in top 5 and bottom 5\nprint(\"Top 10 movie indices for each user in top 5:\")\nfor user_id, movie_indices in top10_movie_indices_top5.items():\n    print(f\"User {user_id}: {movie_indices}\")\n\nprint(\"\\nTest movie indices for each user in top 5:\")\nfor user_id, movie_index in test_movie_indices_top5.items():\n    print(f\"User {user_id}: {movie_index}\")\n\nprint(\"\\nTop 10 movie indices for each user in bottom 5:\")\nfor user_id, movie_indices in top10_movie_indices_bottom5.items():\n    print(f\"User {user_id}: {movie_indices}\")\n\nprint(\"\\nTest movie indices for each user in bottom 5:\")\nfor user_id, movie_index in test_movie_indices_bottom5.items():\n    print(f\"User {user_id}: {movie_index}\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\n# Initialize variables to track NDCG@10\nndcg_sum = 0\nnum_users = 0\n\n# Iterate over each user\nfor user_id in df['userId'].unique():\n    if user_id == 610:\n        continue \n    \n    # Get movies rated by the user\n    rated_movies = df[df['userId'] == user_id]\n    \n    # Sample 100 unrated movie IDs if available\n    unrated_movie_ids = df[~df['movieId'].isin(rated_movies['movieId'])]['movieId'].unique()\n    sampled_movie_ids = np.random.choice(unrated_movie_ids, size=min(100, len(unrated_movie_ids)), replace=False)\n    \n    # Append the highest rated movie for the user\n    highest_rated_movie_id = rated_movies.nlargest(1, 'rating')['movieId'].values[0]\n    sampled_movie_ids = np.append(sampled_movie_ids, highest_rated_movie_id)\n    \n    # Initialize list to store movie ratings\n    movie_ratings = []\n    \n    # Iterate over each sampled movie\n    for movie_id in sampled_movie_ids:\n        # One-hot encode user and movie\n        user_tensor = torch.tensor([user_id], dtype=torch.long)\n        movie_tensor = torch.tensor([movie_id], dtype=torch.long)\n        \n        user_onehot = torch.zeros(1, n_users)\n        user_onehot[0, user_id] = 1.0\n        \n        movie_onehot = torch.zeros(1, n_movies)\n        movie_onehot[0, movie_id] = 1.0\n        \n        # Get predictions from the model\n        model_output = model(user_onehot, movie_onehot)\n        \n        # Store the movie ID and its predicted rating\n        movie_ratings.append((movie_id, model_output.item()))  # Assuming model_output contains the predicted rating\n    \n    # Sort the movie ratings based on predicted ratings\n    movie_ratings.sort(key=lambda x: x[1], reverse=True)\n    \n    # Get the index of the highest rated item for the user\n    highest_rated_item_index = np.where(sampled_movie_ids == highest_rated_movie_id)[0][0]\n    \n    # Compute DCG@10 for the user\n    dcg = 0\n    for rank, (movie_id, _) in enumerate(movie_ratings[:10], start=1):\n        relevance = 1 if np.where(sampled_movie_ids == movie_id)[0][0] == highest_rated_item_index else 0\n        dcg += (2 ** relevance - 1) / np.log2(rank + 1)\n    \n    # Compute ideal DCG@10 for the user\n    ideal_dcg = sum((2 ** 1 - 1) / np.log2(rank + 1) for rank in range(1, min(11, len(rated_movies) + 1)))\n    \n    # Accumulate NDCG@10\n    if ideal_dcg > 0:\n        ndcg_sum += dcg / ideal_dcg\n        num_users += 1\n\n# Calculate average NDCG@10\nndcg_at_10 = ndcg_sum / num_users if num_users > 0 else 0\nprint(\"Average NDCG@10:\", ndcg_at_10)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\n# Initialize variables to track NDCG@10 and the number of users\nndcg_sum = 0\nnum_users = 0\n\n# Iterate over each user\nfor user_id in df['userId'].unique():\n    if user_id == 610:\n        continue \n    \n    # Get movies rated by the user\n    rated_movies = df[df['userId'] == user_id]\n    \n    # Sample 100 unrated movie IDs if available\n    unrated_movie_ids = df[~df['movieId'].isin(rated_movies['movieId'])]['movieId'].unique()\n    sampled_movie_ids = np.random.choice(unrated_movie_ids, size=min(100, len(unrated_movie_ids)), replace=False)\n    \n    # Append the highest rated movie for the user\n    highest_rated_movie_id = rated_movies.nlargest(1, 'rating')['movieId'].values[0]\n    sampled_movie_ids = np.append(sampled_movie_ids, highest_rated_movie_id)\n    \n    # Initialize list to store movie ratings\n    movie_ratings = []\n    \n    # Iterate over each sampled movie\n    for movie_id in sampled_movie_ids:\n        # One-hot encode user and movie\n        user_tensor = torch.tensor([user_id], dtype=torch.long)\n        movie_tensor = torch.tensor([movie_id], dtype=torch.long)\n        \n        user_onehot = torch.zeros(1, n_users)\n        user_onehot[0, user_id] = 1.0\n        \n        movie_onehot = torch.zeros(1, n_movies)\n        movie_onehot[0, movie_id] = 1.0\n        \n        # Get predictions from the model\n        model_output = model(user_onehot, movie_onehot)\n        \n        # Store the movie ID and its predicted rating\n        movie_ratings.append((movie_id, model_output.item()))  # Assuming model_output contains the predicted rating\n    \n    # Sort the movie ratings based on predicted ratings\n    movie_ratings.sort(key=lambda x: x[1], reverse=True)\n    \n    # Check if the test movie is in the top 10 recommendations\n    if highest_rated_movie_id in [movie_id for movie_id, _ in movie_ratings[:10]]:\n        num_users += 1  # Increment the number of users\n    \n        # Get the index of the highest rated item for the user\n        highest_rated_item_index = np.where(sampled_movie_ids == highest_rated_movie_id)[0][0]\n        \n        # Compute DCG@10 for the user\n        dcg = 0\n        for rank, (movie_id, _) in enumerate(movie_ratings[:10], start=1):\n            relevance = 1 if np.where(sampled_movie_ids == movie_id)[0][0] == highest_rated_item_index else 0\n            dcg += (2 ** relevance - 1) / np.log2(rank + 1)\n        \n        # Compute ideal DCG@10 for the user\n        ideal_dcg = sum((2 ** 1 - 1) / np.log2(rank + 1) for rank in range(1, min(11, len(rated_movies) + 1)))\n        \n        # Accumulate NDCG@10\n        if ideal_dcg > 0:\n            ndcg_sum += dcg / ideal_dcg\n\n# Calculate average NDCG@10\nndcg_at_10 = ndcg_sum / num_users if num_users > 0 else 0\nprint(\"NDCG@10:\", ndcg_at_10)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\n# Get the number of ratings provided by each user\nuser_rating_counts = df['userId'].value_counts()\n\n# Sort users based on the number of ratings they have provided\nsorted_users = user_rating_counts.index.tolist()\n\n# Get the top 20 and bottom 20 frequent users\ntop_20_users = sorted_users[:20]\nbottom_20_users = sorted_users[-20:]\n\n# Function to calculate NDCG@10 for a given set of users\ndef calculate_ndcg(users):\n    # Initialize variables to track NDCG@10 and the number of users\n    ndcg_sum = 0\n    num_users = 0\n\n    # Iterate over each user\n    for user_id in users:\n        if user_id == 610:\n            continue \n        # Get movies rated by the user\n        rated_movies = df[df['userId'] == user_id]\n\n        # Sample 100 unrated movie IDs if available\n        unrated_movie_ids = df[~df['movieId'].isin(rated_movies['movieId'])]['movieId'].unique()\n        sampled_movie_ids = np.random.choice(unrated_movie_ids, size=min(100, len(unrated_movie_ids)), replace=False)\n\n        # Append the highest rated movie for the user\n        highest_rated_movie_id = rated_movies.nlargest(1, 'rating')['movieId'].values[0]\n        sampled_movie_ids = np.append(sampled_movie_ids, highest_rated_movie_id)\n\n        # Initialize list to store movie ratings\n        movie_ratings = []\n\n        # Iterate over each sampled movie\n        for movie_id in sampled_movie_ids:\n            # One-hot encode user and movie (assuming n_users and n_movies are defined)\n            user_tensor = torch.tensor([user_id], dtype=torch.long)\n            movie_tensor = torch.tensor([movie_id], dtype=torch.long)\n            user_onehot = torch.zeros(1, n_users)\n            user_onehot[0, user_id] = 1.0\n            movie_onehot = torch.zeros(1, n_movies)\n            movie_onehot[0, movie_id] = 1.0\n\n            # Get predictions from the model\n            model_output = model(user_onehot, movie_onehot)\n\n            # Store the movie ID and its predicted rating\n            movie_ratings.append((movie_id, model_output.item()))\n\n        # Sort the movie ratings based on predicted ratings\n        movie_ratings.sort(key=lambda x: x[1], reverse=True)\n\n        # Check if the test movie is in the top 10 recommendations\n        if highest_rated_movie_id in [movie_id for movie_id, _ in movie_ratings[:10]]:\n            num_users += 1  # Increment the number of users\n\n            # Get the index of the highest rated item for the user\n            highest_rated_item_index = np.where(sampled_movie_ids == highest_rated_movie_id)[0][0]\n\n            # Compute DCG@10 for the user\n            dcg = 0\n            for rank, (movie_id, _) in enumerate(movie_ratings[:10], start=1):\n                relevance = 1 if np.where(sampled_movie_ids == movie_id)[0][0] == highest_rated_item_index else 0\n                dcg += (2 ** relevance - 1) / np.log2(rank + 1)\n\n            # Compute ideal DCG@10 for the user\n            ideal_dcg = sum((2 ** 1 - 1) / np.log2(rank + 1) for rank in range(1, min(11, len(rated_movies) + 1)))\n\n            # Accumulate NDCG@10\n            if ideal_dcg > 0:\n                ndcg_sum += dcg / ideal_dcg\n\n    # Calculate average NDCG@10\n    average_ndcg_at_10 = ndcg_sum / num_users if num_users > 0 else 0\n    return average_ndcg_at_10\n\n# Calculate NDCG@10 for the top 20 frequent users\nndcg_top_20 = calculate_ndcg(top_20_users)\nprint(\"NDCG@10 for top 20 frequent users:\", ndcg_top_20)\n\n# Calculate NDCG@10 for the bottom 20 frequent users\nndcg_bottom_20 = calculate_ndcg(bottom_20_users)\nprint(\"NDCG@10 for bottom 20 frequent users:\", ndcg_bottom_20)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\n# Initialize variables to track hits, DCG, and IDCG\nhits_count = 0\ndcg_sum = 0\nidcg_sum = 0\n\n# Iterate over each user\nfor user_id in df['userId'].unique():\n    if user_id == 610:\n        continue \n    # Get movies rated by the user\n    rated_movies = df[df['userId'] == user_id]\n    \n    # Sample 100 unrated movie IDs if available\n    unrated_movie_ids = df[~df['movieId'].isin(rated_movies['movieId'])]['movieId'].unique()\n    sampled_movie_ids = np.random.choice(unrated_movie_ids, size=min(100, len(unrated_movie_ids)), replace=False)\n    \n    # Append the highest rated movie for the user\n    highest_rated_movie_id = rated_movies.nlargest(1, 'rating')['movieId'].values[0]\n    sampled_movie_ids = np.append(sampled_movie_ids, highest_rated_movie_id)\n    \n    # Initialize list to store movie ratings\n    movie_ratings = []\n    \n    # Iterate over each sampled movie\n    for movie_id in sampled_movie_ids:\n        # One-hot encode user and movie\n        user_tensor = torch.tensor([user_id], dtype=torch.long)\n        movie_tensor = torch.tensor([movie_id], dtype=torch.long)\n        \n        user_onehot = torch.zeros(1, n_users)\n        user_onehot[0, user_id] = 1.0\n        \n        movie_onehot = torch.zeros(1, n_movies)\n        movie_onehot[0, movie_id] = 1.0\n        \n        # Get predictions from the model\n        model_output = model(user_onehot, movie_onehot)\n        \n        # Store the movie ID and its predicted rating\n        movie_ratings.append((movie_id, model_output.item()))  # Assuming model_output contains the predicted rating\n    \n    # Sort the movie ratings based on predicted ratings\n    movie_ratings.sort(key=lambda x: x[1], reverse=True)\n    \n    # Get the index of the highest rated item for the user\n    highest_rated_item_index = np.where(sampled_movie_ids == highest_rated_movie_id)[0][0]\n    \n    # Compute DCG@10 for the user\n    dcg = 0\n    for rank, (movie_id, _) in enumerate(movie_ratings[:10], start=1):\n        relevance = 1 if np.where(sampled_movie_ids == movie_id)[0][0] == highest_rated_item_index else 0\n        dcg += (2 ** relevance - 1) / np.log2(rank + 1)\n    \n    # Compute ideal DCG@10 for the user\n    ideal_dcg = sum((2 ** 1 - 1) / np.log2(rank + 1) for rank in range(1, min(11, len(rated_movies) + 1)))\n    \n    # Update sums\n    hits_count += 1 if highest_rated_movie_id in [movie_id for movie_id, _ in movie_ratings[:10]] else 0\n    dcg_sum += dcg\n    idcg_sum += ideal_dcg\n\n# Calculate NDCG@10\nndcg = dcg_sum / idcg_sum if idcg_sum > 0 else 0\nhit_rate = hits_count / total_users if total_users > 0 else 0\n\n#print(\"Hit rate:\", hit_rate)\nprint(\"NDCG@10:\", ndcg)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\n# Initialize variables to track DCG and IDCG\ndcg_sum = 0\nidcg_sum = 0\n\n# Iterate over each user\nfor user_id in df['userId'].unique():\n    if user_id == 610:\n        continue \n    # Get movies rated by the user\n    rated_movies = df[df['userId'] == user_id]\n    \n    # Sample 100 unrated movie IDs if available\n    unrated_movie_ids = df[~df['movieId'].isin(rated_movies['movieId'])]['movieId'].unique()\n    sampled_movie_ids = np.random.choice(unrated_movie_ids, size=min(100, len(unrated_movie_ids)), replace=False)\n    \n    # Append the highest rated movie for the user\n    highest_rated_movie_id = rated_movies.nlargest(1, 'rating')['movieId'].values[0]\n    sampled_movie_ids = np.append(sampled_movie_ids, highest_rated_movie_id)\n    \n    # Initialize list to store movie ratings\n    movie_ratings = []\n    \n    # Iterate over each sampled movie\n    for movie_id in sampled_movie_ids:\n        # One-hot encode user and movie\n        user_tensor = torch.tensor([user_id], dtype=torch.long)\n        movie_tensor = torch.tensor([movie_id], dtype=torch.long)\n        \n        user_onehot = torch.zeros(1, n_users)\n        user_onehot[0, user_id] = 1.0\n        \n        movie_onehot = torch.zeros(1, n_movies)\n        movie_onehot[0, movie_id] = 1.0\n        \n        # Get predictions from the model\n        model_output = model(user_onehot, movie_onehot)\n        \n        # Store the movie ID and its predicted rating\n        movie_ratings.append((movie_id, model_output.item()))  # Assuming model_output contains the predicted rating\n    \n    # Sort the movie ratings based on predicted ratings\n    movie_ratings.sort(key=lambda x: x[1], reverse=True)\n    \n    # Get the relevance scores (ratings) for the recommended movies\n    relevance_scores = [rated_movies[rated_movies['movieId'] == movie_id]['rating'].values[0] if movie_id in rated_movies['movieId'].values else 0 for movie_id, _ in movie_ratings[:10]]\n    \n    # Calculate DCG\n    dcg = np.sum(relevance_scores / np.log2(np.arange(2, len(relevance_scores) + 2)))\n    \n    # Calculate IDCG\n    ideal_relevance_scores = sorted(rated_movies['rating'].values, reverse=True)[:min(10, len(rated_movies))]\n    idcg = np.sum(ideal_relevance_scores / np.log2(np.arange(2, len(ideal_relevance_scores) + 2)))\n    \n    # Update sums\n    dcg_sum += dcg\n    idcg_sum += idcg\n\n# Calculate NDCG@10\n# Calculate NDCG@10\nndcg = (dcg_sum * 10) / idcg_sum if idcg_sum > 0 else 0\nprint(\"NDCG@10:\", ndcg)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set the model to evaluation mode\nmodel.eval()\n\n# Initialize variables to track hits\nhits_count = 0\ntotal_users = 0\n\n# Specify the user for evaluation\nuser_id = 2  # Assuming the user ID is 123\n\n# Get movies rated by the user\nrated_movies = df[df['userId'] == user_id]\n\n# Sample 100 unrated movie IDs if available\nunrated_movie_ids = df[~df['movieId'].isin(rated_movies['movieId'])]['movieId'].unique()\nsampled_movie_ids = np.random.choice(unrated_movie_ids, size=min(100, len(unrated_movie_ids)), replace=False)\n\n# Append the highest rated movie for the user\nhighest_rated_movie_id = rated_movies.nlargest(1, 'rating')['movieId'].values[0]\nsampled_movie_ids = np.append(sampled_movie_ids, highest_rated_movie_id)\n\n# Initialize list to store movie ratings\nmovie_ratings = []\n\n# Iterate over each sampled movie\nfor movie_id in sampled_movie_ids:\n    # One-hot encode user and movie\n    user_tensor = torch.tensor([user_id], dtype=torch.long)\n    movie_tensor = torch.tensor([movie_id], dtype=torch.long)\n    \n    user_onehot = torch.zeros(1, n_users)\n    user_onehot[0, user_id] = 1.0\n    \n    movie_onehot = torch.zeros(1, n_movies)\n    movie_onehot[0, movie_id] = 1.0\n    \n    # Get predictions from the model\n    model_output = model(user_onehot, movie_onehot)\n    \n    # Store the movie ID and its predicted rating\n    movie_ratings.append((movie_id, model_output.item()))  # Assuming model_output contains the predicted rating\n\n# Sort the movie ratings based on predicted ratings\nmovie_ratings.sort(key=lambda x: x[1], reverse=True)\n\n# Print the test movie ID\nprint(\"Test Movie ID:\", highest_rated_movie_id)\n\n# Print the movie indices of top 10 recommendations\ntop_10_recommendations = [movie_id for movie_id, _ in movie_ratings[:10]]\nprint(\"Top 10 Recommended Movie IDs:\", top_10_recommendations)\n\n# Map the indices back to original movieIds\ntop_10_original_movieIds = [sampled_movie_ids[np.where(sampled_movie_ids == movie_id)[0][0]] for movie_id in top_10_recommendations]\nprint(\"Top 10 Recommended Original Movie IDs:\", top_10_original_movieIds)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check if the highest rated item is among the top 10 recommendations for this user\nif highest_rated_movie_id in top_10_original_movieIds:\n    print(\"Hit: Highest rated movie is among the top 10 recommended movies for User\", user_id)\n    hits_count += 1\nelse:\n    print(\"Miss: Highest rated movie is not among the top 10 recommended movies for User\", user_id)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Choose the first user ID (assuming user IDs start from 1)\nfirst_user_id = 414\n\n# Filter the training set for the first user\ntraining_ratings_first_user = df_train[df_train['userId'] == first_user_id]\n\n# Filter the validation set for the first user\nvalidation_ratings_first_user = df_valid[df_valid['userId'] == first_user_id]\n\n# Print information for the training set\nprint(f\"Training Set - User {first_user_id} Ratings:\")\nprint(training_ratings_first_user[['movieId', 'rating']])\n\n# Print information for the validation set\nprint(f\"\\nValidation Set - User {first_user_id} Ratings:\")\nprint(validation_ratings_first_user[['movieId', 'rating']])\n\n# Check if movie ID 100 is present in the training set for the first user\nis_movie_100_in_training = 100 in training_ratings_first_user['movieId'].values\nprint(f\"Is Movie ID 100 present in the training set for User {first_user_id}? {is_movie_100_in_training}\")\n\n# Check if movie ID 100 is present in the validation set for the first user\nis_movie_100_in_validation = 100 in validation_ratings_first_user['movieId'].values\nprint(f\"Is Movie ID 100 present in the validation set for User {first_user_id}? {is_movie_100_in_validation}\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set the model to evaluation mode\nmodel.eval()\n\n# Initialize variables to track hits\nhits_count = 0\ntotal_users = 0\n\n# Iterate over each user\nfor user_id in df['userId'].unique():\n    if user_id == 610:\n        continue \n    # Get movies rated by the user\n    rated_movies = df[df['userId'] == user_id]\n    \n    # Check if the highest rated movie for the user is 5\n    if rated_movies['rating'].max() == 5:\n        # Sample 100 unrated movie IDs if available\n        unrated_movie_ids = df[~df['movieId'].isin(rated_movies['movieId'])]['movieId'].unique()\n        sampled_movie_ids = np.random.choice(unrated_movie_ids, size=min(100, len(unrated_movie_ids)), replace=False)\n        \n        # Append the highest rated movie for the user\n        highest_rated_movie_id = rated_movies.nlargest(1, 'rating')['movieId'].values[0]\n        sampled_movie_ids = np.append(sampled_movie_ids, highest_rated_movie_id)\n        \n        # Initialize list to store movie ratings\n        movie_ratings = []\n        \n        # Iterate over each sampled movie\n        for movie_id in sampled_movie_ids:\n            # One-hot encode user and movie\n            user_tensor = torch.tensor([user_id], dtype=torch.long)\n            movie_tensor = torch.tensor([movie_id], dtype=torch.long)\n            \n            user_onehot = torch.zeros(1, n_users)\n            user_onehot[0, user_id] = 1.0\n            \n            movie_onehot = torch.zeros(1, n_movies)\n            movie_onehot[0, movie_id] = 1.0\n            \n            # Get predictions from the model\n            model_output = model(user_onehot, movie_onehot)\n            \n            # Store the movie ID and its predicted rating\n            movie_ratings.append((movie_id, model_output.item()))  # Assuming model_output contains the predicted rating\n        \n        # Sort the movie ratings based on predicted ratings\n        movie_ratings.sort(key=lambda x: x[1], reverse=True)\n        \n        # Check if the highest rated item is among the top 10 recommendations\n        top_10_recommendations = [movie_id for movie_id, _ in movie_ratings[:5]]\n        if highest_rated_movie_id in top_10_recommendations:\n            hits_count += 1\n        \n        total_users += 1\n\n# Calculate hit rate\nhit_rate = hits_count / total_users if total_users > 0 else 0\nprint(\"Hit rate:\", hit_rate)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set the model to evaluation mode\nmodel.eval()\n\n# Initialize variables to track hits\nhits_count_top20 = 0\nhits_count_bottom20 = 0\ntotal_users_top20 = 0\ntotal_users_bottom20 = 0\n\n# Get the number of ratings provided by each user\nuser_rating_counts = df['userId'].value_counts()\n\n# Sort users based on the number of ratings they have provided\nsorted_users = user_rating_counts.index.tolist()\n\n# Select the top 20 and bottom 20 frequent users\ntop20_users = sorted_users[:20]\nbottom20_users = sorted_users[-20:]\n\n# Iterate over each user\nfor user_id in df['userId'].unique():\n    # Skip user 610\n    if user_id == 610:\n        continue\n    \n    # Get movies rated by the user\n    rated_movies = df[df['userId'] == user_id]\n    \n    # Sample 100 unrated movie IDs if available\n    unrated_movie_ids = df[~df['movieId'].isin(rated_movies['movieId'])]['movieId'].unique()\n    sampled_movie_ids = np.random.choice(unrated_movie_ids, size=min(100, len(unrated_movie_ids)), replace=False)\n    \n    # Append the highest rated movie for the user\n    highest_rated_movie_id = rated_movies.nlargest(1, 'rating')['movieId'].values[0]\n    sampled_movie_ids = np.append(sampled_movie_ids, highest_rated_movie_id)\n    \n    # Initialize list to store movie ratings\n    movie_ratings = []\n    \n    # Iterate over each sampled movie\n    for movie_id in sampled_movie_ids:\n        # One-hot encode user and movie\n        user_tensor = torch.tensor([user_id], dtype=torch.long)\n        movie_tensor = torch.tensor([movie_id], dtype=torch.long)\n        \n        user_onehot = torch.zeros(1, n_users)\n        user_onehot[0, user_id] = 1.0\n        \n        movie_onehot = torch.zeros(1, n_movies)\n        movie_onehot[0, movie_id] = 1.0\n        \n        # Get predictions from the model\n        model_output = model(user_onehot, movie_onehot)\n        \n        # Store the movie ID and its predicted rating\n        movie_ratings.append((movie_id, model_output.item()))  # Assuming model_output contains the predicted rating\n    \n    # Sort the movie ratings based on predicted ratings\n    movie_ratings.sort(key=lambda x: x[1], reverse=True)\n    \n    # Check if the highest rated item is among the top 10 recommendations\n    top_10_recommendations = [movie_id for movie_id, _ in movie_ratings[:5]]\n    if user_id in top20_users:\n        if highest_rated_movie_id in top_10_recommendations:\n            hits_count_top20 += 1\n        total_users_top20 += 1\n    elif user_id in bottom20_users:\n        if highest_rated_movie_id in top_10_recommendations:\n            hits_count_bottom20 += 1\n        total_users_bottom20 += 1\n\n# Calculate hit rate for top 20 and bottom 20 users\nhit_rate_top20 = hits_count_top20 / total_users_top20 if total_users_top20 > 0 else 0\nhit_rate_bottom20 = hits_count_bottom20 / total_users_bottom20 if total_users_bottom20 > 0 else 0\n\nprint(\"Hit rate for top 20 frequent users:\", hit_rate_top20)\nprint(\"Hit rate for bottom 20 frequent users:\", hit_rate_bottom20)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}